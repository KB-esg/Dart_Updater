import os
from datetime import datetime, timedelta
import json
import time
import re
import gspread
from google.oauth2.service_account import Credentials
import OpenDartReader
import requests
from bs4 import BeautifulSoup
import pandas as pd
import xml.etree.ElementTree as ET
from urllib.parse import urljoin, urlparse
import zipfile
import io
import openpyxl
from openpyxl import load_workbook

# HTML í…Œì´ë¸” íŒŒì„œ ëŒ€ì•ˆ êµ¬í˜„
try:
    from html_table_parser import parser_functions as parser
    HTML_PARSER_AVAILABLE = True
    print("âœ… html_table_parser ë¡œë“œ ì„±ê³µ")
except ImportError:
    try:
        from html_table_parser_python3 import parser_functions as parser
        HTML_PARSER_AVAILABLE = True
        print("âœ… html_table_parser_python3 ë¡œë“œ ì„±ê³µ")
    except ImportError:
        HTML_PARSER_AVAILABLE = False
        print("âš ï¸ HTML íŒŒì„œ íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ë‚´ì¥ íŒŒì„œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

class DualSystemDartUpdater:
    """XBRL/HTML ì´ì›í™” ê´€ë¦¬ ì‹œìŠ¤í…œ"""
    
    # HTML ìŠ¤í¬ë˜í•‘ ëŒ€ìƒ ì‹œíŠ¸ (ê¸°ì¡´ ë°©ì‹, ì£¼ì„ ì œì™¸)
    HTML_TARGET_SHEETS = [
        'I. íšŒì‚¬ì˜ ê°œìš”', 'II. ì‚¬ì—…ì˜ ë‚´ìš©', '1. ì‚¬ì—…ì˜ ê°œìš”', '2. ì£¼ìš” ì œí’ˆ ë° ì„œë¹„ìŠ¤',
        '3. ì›ì¬ë£Œ ë° ìƒì‚°ì„¤ë¹„', '4. ë§¤ì¶œ ë° ìˆ˜ì£¼ìƒí™©', '5. ìœ„í—˜ê´€ë¦¬ ë° íŒŒìƒê±°ë˜',
        '6. ì£¼ìš”ê³„ì•½ ë° ì—°êµ¬í™œë™', '7. ê¸°íƒ€ ì°¸ê³  ì‚¬í•­', '1. ìš”ì•½ì¬ë¬´ì •ë³´',
        '6. ë°°ë‹¹ì— ê´€í•œ ì‚¬í•­', '8. ê¸°íƒ€ ì¬ë¬´ì— ê´€í•œ ì‚¬í•­', 'VII. ì£¼ì£¼ì— ê´€í•œ ì‚¬í•­',
        'VIII. ì„ì› ë° ì§ì› ë“±ì— ê´€í•œ ì‚¬í•­', 'X. ëŒ€ì£¼ì£¼ ë“±ê³¼ì˜ ê±°ë˜ë‚´ìš©',
        'XI. ê·¸ ë°–ì— íˆ¬ìì ë³´í˜¸ë¥¼ ìœ„í•˜ì—¬ í•„ìš”í•œ ì‚¬í•­'
    ]
    
    # XBRL ìš°ì„  ì²˜ë¦¬ ëŒ€ìƒ ì‹œíŠ¸ (ì¬ë¬´ì œí‘œ + ì£¼ì„)
    XBRL_TARGET_SHEETS = [
        '2. ì—°ê²°ì¬ë¬´ì œí‘œ',
        '4. ì¬ë¬´ì œí‘œ',
        '3. ì—°ê²°ì¬ë¬´ì œí‘œ ì£¼ì„',
        '5. ì¬ë¬´ì œí‘œ ì£¼ì„'
    ]

    def __init__(self, company_config):
        """ì´ˆê¸°í™” - company_configëŠ” ymlì—ì„œ ì½ì–´ì˜¨ ì„¤ì •"""
        self.corp_code = company_config['corp_code']
        self.company_name = company_config['company_name']
        self.spreadsheet_var_name = company_config['spreadsheet_var']
        
        # í™˜ê²½ë³€ìˆ˜ í™•ì¸
        print("í™˜ê²½ë³€ìˆ˜ í™•ì¸:")
        required_vars = ['DART_API_KEY', 'GOOGLE_CREDENTIALS', self.spreadsheet_var_name, 
                        'TELEGRAM_BOT_TOKEN', 'TELEGRAM_CHANNEL_ID']
        for var in required_vars:
            if var in os.environ:
                value = os.environ[var]
                if len(value) > 4:
                    if len(value) > 20:
                        masked_value = value[:6] + '...' + value[-4:-2] + '**'
                    else:
                        masked_value = value[:-2] + '**'
                    print(f"âœ… {var}: {masked_value} (ê¸¸ì´: {len(value)})")
                else:
                    print(f"âš ï¸ {var}: ê°’ì´ ë„ˆë¬´ ì§§ìŒ (ê¸¸ì´: {len(value)})")
            else:
                print(f"âŒ {var}: ì„¤ì •ë˜ì§€ ì•ŠìŒ")
        
        if self.spreadsheet_var_name not in os.environ:
            raise ValueError(f"{self.spreadsheet_var_name} í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
        self.credentials = self.get_credentials()
        self.gc = gspread.authorize(self.credentials)
        self.dart = OpenDartReader(os.environ['DART_API_KEY'])
        self.workbook = self.gc.open_by_key(os.environ[self.spreadsheet_var_name])
        self.telegram_bot_token = os.environ.get('TELEGRAM_BOT_TOKEN')
        self.telegram_channel_id = os.environ.get('TELEGRAM_CHANNEL_ID')
        
        # ì²˜ë¦¬ ê²°ê³¼ ì¶”ì 
        self.processing_results = {
            'xbrl_xlsx_success': [],
            'xbrl_xlsx_failed': [],
            'xbrl_success': [],
            'xbrl_failed': [],
            'html_success': [],
            'html_failed': [],
            'total_processed': 0
        }
        
        # XBRL ë„¤ì„ìŠ¤í˜ì´ìŠ¤
        self.xbrl_namespaces = {
            'xbrl': 'http://www.xbrl.org/2003/instance',
            'ifrs': 'http://xbrl.ifrs.org/taxonomy/2021-03-24/ifrs',
            'ifrs-full': 'http://xbrl.ifrs.org/taxonomy/2021-03-24/ifrs-full',
            'dart': 'http://dart.fss.or.kr/xbrl/taxonomy/kr-gaap',
            'link': 'http://www.xbrl.org/2003/linkbase',
            'xlink': 'http://www.w3.org/1999/xlink'
        }

    def get_credentials(self):
        """Google Sheets ì¸ì¦ ì„¤ì •"""
        creds_json = json.loads(os.environ['GOOGLE_CREDENTIALS'])
        scopes = [
            'https://www.googleapis.com/auth/spreadsheets',
            'https://www.googleapis.com/auth/drive'
        ]
        return Credentials.from_service_account_info(creds_json, scopes=scopes)

    def update_dart_reports(self):
        """DART ë³´ê³ ì„œ ë°ì´í„° ì—…ë°ì´íŠ¸ (ì´ì›í™” ì‹œìŠ¤í…œ)"""
        start_date, end_date = self.get_recent_dates()
        report_list = self.dart.list(self.corp_code, start_date, end_date, kind='A', final='T')
        
        if not report_list.empty:
            print(f"ğŸ“‹ ë°œê²¬ëœ ë³´ê³ ì„œ: {len(report_list)}ê°œ")
            
            for _, report in report_list.iterrows():
                print(f"\nğŸ“„ ë³´ê³ ì„œ ì²˜ë¦¬ ì‹œì‘: {report['report_nm']} (ì ‘ìˆ˜ë²ˆí˜¸: {report['rcept_no']})")
                self.processing_results['total_processed'] += 1
                
                # 1ë‹¨ê³„: XBRL Excel íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë° ì²˜ë¦¬ ì‹œë„ (ìƒˆë¡œìš´ ë°©ì‹)
                xbrl_xlsx_success = self.process_xbrl_excel_files(report['rcept_no'])
                
                # 2ë‹¨ê³„: ê¸°ì¡´ XBRL ì „ìš© ì²˜ë¦¬ ì‹œë„ (ê¸°ì¡´ ë°©ì‹ ë°±ì—…)
                xbrl_success = False
                if not xbrl_xlsx_success:
                    xbrl_success = self.process_xbrl_sheets(report['rcept_no'])
                
                # 3ë‹¨ê³„: HTML ì‹œíŠ¸ ì²˜ë¦¬ (í•­ìƒ ì‹¤í–‰)
                html_success = self.process_html_sheets(report['rcept_no'])
                
                # 4ë‹¨ê³„: ì²˜ë¦¬ ê²°ê³¼ ê¸°ë¡
                self.record_processing_result(report, xbrl_xlsx_success or xbrl_success, html_success)
                
        else:
            print("ğŸ“­ ìµœê·¼ 3ê°œì›” ë‚´ ìƒˆë¡œìš´ ë³´ê³ ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        self.print_processing_summary()

    def process_xbrl_excel_files(self, rcept_no):
        """XBRL Excel íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë° ì²˜ë¦¬ (ìƒˆë¡œìš´ ë°©ì‹)"""
        print(f"\nğŸ“Š XBRL Excel íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {rcept_no}")
        
        try:
            # XBRL í˜ì´ì§€ì—ì„œ xbrlExtSeq ì¶”ì¶œ
            xbrl_ext_seq = self.get_xbrl_ext_seq(rcept_no)
            if not xbrl_ext_seq:
                print("âš ï¸ xbrlExtSeqë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return False
            
            print(f"ğŸ“ xbrlExtSeq: {xbrl_ext_seq}")
            
            # ì¬ë¬´ì œí‘œ Excel ë‹¤ìš´ë¡œë“œ ë° ì²˜ë¦¬
            financial_success = self.download_and_process_financial_statements(xbrl_ext_seq, rcept_no)
            
            # ì¬ë¬´ì œí‘œì£¼ì„ Excel ë‹¤ìš´ë¡œë“œ ë° ì²˜ë¦¬
            notes_success = self.download_and_process_notes(xbrl_ext_seq, rcept_no)
            
            if financial_success or notes_success:
                print(f"âœ… XBRL Excel íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ")
                return True
            else:
                print(f"âŒ XBRL Excel íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            print(f"âŒ XBRL Excel íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return False

    def get_xbrl_ext_seq(self, rcept_no):
        """XBRL í˜ì´ì§€ì—ì„œ xbrlExtSeq ì¶”ì¶œ"""
        try:
            # XBRL ë·°ì–´ í˜ì´ì§€ ì ‘ê·¼
            viewer_url = f"https://opendart.fss.or.kr/xbrl/viewer/main.do?rcpNo={rcept_no}"
            
            response = requests.get(viewer_url, timeout=30)
            response.raise_for_status()
            
            # HTML íŒŒì‹±
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # JavaScriptì—ì„œ xbrlExtSeq ì¶”ì¶œ ì‹œë„
            scripts = soup.find_all('script')
            for script in scripts:
                if script.string:
                    # viewDoc í•¨ìˆ˜ í˜¸ì¶œì—ì„œ xbrlExtSeq ì°¾ê¸°
                    match = re.search(r"viewDoc\s*\(\s*'(\d+)'", script.string)
                    if match:
                        return match.group(1)
            
            # onclick ì†ì„±ì—ì„œ ì°¾ê¸°
            onclick_elements = soup.find_all(attrs={'onclick': True})
            for elem in onclick_elements:
                match = re.search(r"viewDoc\s*\(\s*'(\d+)'", elem.get('onclick', ''))
                if match:
                    return match.group(1)
            
            # iframe srcì—ì„œ ì°¾ê¸°
            iframes = soup.find_all('iframe')
            for iframe in iframes:
                src = iframe.get('src', '')
                match = re.search(r'xbrlExtSeq=(\d+)', src)
                if match:
                    return match.group(1)
            
            print("âš ï¸ xbrlExtSeqë¥¼ HTMLì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return None
            
        except Exception as e:
            print(f"âŒ xbrlExtSeq ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            return None

    def download_and_process_financial_statements(self, xbrl_ext_seq, rcept_no):
        """ì¬ë¬´ì œí‘œ Excel ë‹¤ìš´ë¡œë“œ ë° ì²˜ë¦¬"""
        try:
            print(f"ğŸ“Š ì¬ë¬´ì œí‘œ Excel ë‹¤ìš´ë¡œë“œ ì¤‘...")
            
            # ë‹¤ìš´ë¡œë“œ URL
            download_url = f"https://opendart.fss.or.kr/xbrl/viewer/download/excel/financialStatements.do?xbrlExtSeq={xbrl_ext_seq}&lang=ko"
            
            # Excel íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            response = requests.get(download_url, timeout=60)
            response.raise_for_status()
            
            # Excel íŒŒì¼ì„ ë©”ëª¨ë¦¬ì—ì„œ ì²˜ë¦¬
            excel_data = io.BytesIO(response.content)
            wb = load_workbook(excel_data, data_only=True)
            
            print(f"ğŸ“‹ ì¬ë¬´ì œí‘œ ì‹œíŠ¸ ëª©ë¡: {wb.sheetnames}")
            
            # ê° ì‹œíŠ¸ë¥¼ Google Sheetsì— ì—…ë¡œë“œ
            for sheet_name in wb.sheetnames:
                try:
                    # Excel ì‹œíŠ¸ ë°ì´í„° ì½ê¸°
                    ws = wb[sheet_name]
                    data = []
                    
                    for row in ws.iter_rows(values_only=True):
                        # None ê°’ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ë³€í™˜
                        row_data = [str(cell) if cell is not None else '' for cell in row]
                        if any(row_data):  # ì™„ì „íˆ ë¹ˆ í–‰ì€ ì œì™¸
                            data.append(row_data)
                    
                    if data:
                        # Google Sheetsì— ì‹œíŠ¸ ìƒì„±/ì—…ë°ì´íŠ¸
                        gsheet_name = f"XBRL_{sheet_name}_{rcept_no}"
                        self.update_google_sheet(gsheet_name, data)
                        self.processing_results['xbrl_xlsx_success'].append(gsheet_name)
                        print(f"âœ… ì¬ë¬´ì œí‘œ ì‹œíŠ¸ ì—…ë¡œë“œ ì™„ë£Œ: {gsheet_name}")
                    
                except Exception as sheet_e:
                    print(f"âŒ ì‹œíŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨ {sheet_name}: {str(sheet_e)}")
                    self.processing_results['xbrl_xlsx_failed'].append(sheet_name)
                    continue
            
            return True
            
        except Exception as e:
            print(f"âŒ ì¬ë¬´ì œí‘œ Excel ë‹¤ìš´ë¡œë“œ/ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return False

    def download_and_process_notes(self, xbrl_ext_seq, rcept_no):
        """ì¬ë¬´ì œí‘œì£¼ì„ Excel ë‹¤ìš´ë¡œë“œ ë° ì²˜ë¦¬"""
        try:
            print(f"ğŸ“‘ ì¬ë¬´ì œí‘œì£¼ì„ Excel ë‹¤ìš´ë¡œë“œ ì¤‘...")
            
            # ë‹¤ìš´ë¡œë“œ URL
            download_url = f"https://opendart.fss.or.kr/xbrl/viewer/download/excel/notes.do?xbrlExtSeq={xbrl_ext_seq}&lang=ko"
            
            # Excel íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            response = requests.get(download_url, timeout=60)
            response.raise_for_status()
            
            # Excel íŒŒì¼ì„ ë©”ëª¨ë¦¬ì—ì„œ ì²˜ë¦¬
            excel_data = io.BytesIO(response.content)
            wb = load_workbook(excel_data, data_only=True)
            
            print(f"ğŸ“‹ ì¬ë¬´ì œí‘œì£¼ì„ ì‹œíŠ¸ ëª©ë¡: {wb.sheetnames}")
            
            # ê° ì‹œíŠ¸ë¥¼ Google Sheetsì— ì—…ë¡œë“œ
            for sheet_name in wb.sheetnames:
                try:
                    # Excel ì‹œíŠ¸ ë°ì´í„° ì½ê¸°
                    ws = wb[sheet_name]
                    data = []
                    
                    for row in ws.iter_rows(values_only=True):
                        # None ê°’ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ë³€í™˜
                        row_data = [str(cell) if cell is not None else '' for cell in row]
                        if any(row_data):  # ì™„ì „íˆ ë¹ˆ í–‰ì€ ì œì™¸
                            data.append(row_data)
                    
                    if data:
                        # Google Sheetsì— ì‹œíŠ¸ ìƒì„±/ì—…ë°ì´íŠ¸
                        gsheet_name = f"XBRL_ì£¼ì„_{sheet_name}_{rcept_no}"
                        self.update_google_sheet(gsheet_name, data)
                        self.processing_results['xbrl_xlsx_success'].append(gsheet_name)
                        print(f"âœ… ì¬ë¬´ì œí‘œì£¼ì„ ì‹œíŠ¸ ì—…ë¡œë“œ ì™„ë£Œ: {gsheet_name}")
                    
                except Exception as sheet_e:
                    print(f"âŒ ì‹œíŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨ {sheet_name}: {str(sheet_e)}")
                    self.processing_results['xbrl_xlsx_failed'].append(sheet_name)
                    continue
            
            return True
            
        except Exception as e:
            print(f"âŒ ì¬ë¬´ì œí‘œì£¼ì„ Excel ë‹¤ìš´ë¡œë“œ/ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return False

    def update_google_sheet(self, sheet_name, data):
        """Google Sheets ì—…ë°ì´íŠ¸"""
        try:
            # ì‹œíŠ¸ ì´ë¦„ ê¸¸ì´ ì œí•œ (100ì)
            if len(sheet_name) > 100:
                sheet_name = sheet_name[:97] + "..."
            
            # ê¸°ì¡´ ì‹œíŠ¸ í™•ì¸ ë° ìƒì„±
            try:
                worksheet = self.workbook.worksheet(sheet_name)
                # ê¸°ì¡´ ì‹œíŠ¸ê°€ ìˆìœ¼ë©´ í´ë¦¬ì–´
                worksheet.clear()
            except gspread.exceptions.WorksheetNotFound:
                # ìƒˆ ì‹œíŠ¸ ìƒì„±
                max_rows = max(1000, len(data) + 100)
                max_cols = max(26, len(data[0]) + 5) if data else 26
                worksheet = self.workbook.add_worksheet(sheet_name, max_rows, max_cols)
            
            # ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì—…ë¡œë“œ
            if data:
                # í—¤ë” ì¶”ê°€
                header = [
                    [f"ì²˜ë¦¬ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"],
                    [f"ë°ì´í„° ì¶œì²˜: XBRL Excel ë‹¤ìš´ë¡œë“œ"],
                    []
                ]
                
                all_data = header + data
                
                # ë°°ì¹˜ ì—…ë¡œë“œ
                BATCH_SIZE = 100
                for i in range(0, len(all_data), BATCH_SIZE):
                    batch = all_data[i:i + BATCH_SIZE]
                    
                    try:
                        worksheet.append_rows(batch)
                        time.sleep(1)  # API ì œí•œ íšŒí”¼
                    except gspread.exceptions.APIError as e:
                        if 'Quota exceeded' in str(e):
                            print("API í• ë‹¹ëŸ‰ ì´ˆê³¼. 60ì´ˆ ëŒ€ê¸°...")
                            time.sleep(60)
                            worksheet.append_rows(batch)
                        else:
                            raise e
            
        except Exception as e:
            print(f"âŒ Google Sheets ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
            raise

    # ê¸°ì¡´ ë©”ì„œë“œë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
    def process_xbrl_sheets(self, rcept_no):
        """XBRL ì „ìš© ì‹œíŠ¸ ì²˜ë¦¬ (ê¸°ì¡´ ë°©ì‹)"""
        print(f"\nğŸ”¬ XBRL ë°©ì‹ ì²˜ë¦¬ ì‹œì‘: {rcept_no}")
        
        try:
            # XBRL ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° íŒŒì‹±
            xbrl_content = self.download_xbrl_data(rcept_no)
            parsed_xbrl = self.parse_xbrl_data(xbrl_content)
            
            if not parsed_xbrl.get('financial_data'):
                print("âš ï¸ XBRLì—ì„œ ì¬ë¬´ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return False
            
            # XBRL ì „ìš© ì‹œíŠ¸ì— êµ¬ì¡°í™”ëœ ë°ì´í„° ì €ì¥
            structured_data = self.convert_xbrl_to_structured_data(parsed_xbrl)
            self.update_xbrl_dedicated_sheets(structured_data, rcept_no)
            
            # ì²˜ë¦¬ ê²°ê³¼ ê¸°ë¡
            for sheet_name in self.XBRL_TARGET_SHEETS:
                self.processing_results['xbrl_success'].append(sheet_name)
            
            print(f"âœ… XBRL ë°©ì‹ ì²˜ë¦¬ ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ XBRL ë°©ì‹ ì‹¤íŒ¨: {str(e)}")
            for sheet_name in self.XBRL_TARGET_SHEETS:
                self.processing_results['xbrl_failed'].append(sheet_name)
            return False

    def process_html_sheets(self, rcept_no):
        """HTML ì „ìš© ì‹œíŠ¸ ì²˜ë¦¬"""
        print(f"\nğŸŒ HTML ë°©ì‹ ì²˜ë¦¬ ì‹œì‘: {rcept_no}")
        
        try:
            report_index = self.dart.sub_docs(rcept_no)
            target_docs = report_index[report_index['title'].isin(self.HTML_TARGET_SHEETS)]
            
            print(f"ğŸ“‘ HTML ì²˜ë¦¬ ëŒ€ìƒ ë¬¸ì„œ: {len(target_docs)}ê°œ")
            
            success_count = 0
            for _, doc in target_docs.iterrows():
                try:
                    print(f"ğŸ“„ HTML ë¬¸ì„œ ì²˜ë¦¬: {doc['title']}")
                    self.update_html_worksheet(doc['title'], doc['url'])
                    self.processing_results['html_success'].append(doc['title'])
                    success_count += 1
                    print(f"âœ… HTML ë¬¸ì„œ ì™„ë£Œ: {doc['title']}")
                    
                except Exception as doc_e:
                    print(f"âŒ HTML ë¬¸ì„œ ì‹¤íŒ¨ {doc['title']}: {str(doc_e)}")
                    self.processing_results['html_failed'].append(doc['title'])
                    continue
            
            print(f"âœ… HTML ë°©ì‹ ì²˜ë¦¬ ì™„ë£Œ: {success_count}/{len(target_docs)}ê°œ ì„±ê³µ")
            return success_count > 0
            
        except Exception as e:
            print(f"âŒ HTML ë°©ì‹ ì „ì²´ ì‹¤íŒ¨: {str(e)}")
            return False

    # ë‚˜ë¨¸ì§€ ê¸°ì¡´ ë©”ì„œë“œë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€...
    def update_xbrl_dedicated_sheets(self, structured_data, rcept_no):
        """XBRL ì „ìš© ì‹œíŠ¸ ì—…ë°ì´íŠ¸"""
        print(f"ğŸ“Š XBRL ì „ìš© ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì‹œì‘")
        
        # XBRL ì‹œíŠ¸ëª… ì •ì˜ (êµ¬ë¶„ì„ ìœ„í•´ ì ‘ë‘ì‚¬ ì¶”ê°€)
        xbrl_sheets = {
            'XBRL_ì—°ê²°ì¬ë¬´ì œí‘œ': structured_data,
            'XBRL_ì¬ë¬´ì œí‘œ': structured_data,
            'XBRL_ì—°ê²°ì¬ë¬´ì œí‘œ_ì£¼ì„': self.create_notes_data(structured_data, 'ì—°ê²°', rcept_no),
            'XBRL_ì¬ë¬´ì œí‘œ_ì£¼ì„': self.create_notes_data(structured_data, 'ë³„ë„', rcept_no),
            'XBRL_ì²˜ë¦¬í˜„í™©': self.create_xbrl_status_data(structured_data, rcept_no)
        }
        
        for sheet_name, data in xbrl_sheets.items():
            try:
                # ì‹œíŠ¸ ì¡´ì¬ í™•ì¸ ë° ìƒì„±
                try:
                    worksheet = self.workbook.worksheet(sheet_name)
                except gspread.exceptions.WorksheetNotFound:
                    print(f"ğŸ†• ìƒˆ XBRL ì‹œíŠ¸ ìƒì„±: {sheet_name}")
                    worksheet = self.workbook.add_worksheet(sheet_name, 1000, 15)
                    self.setup_xbrl_sheet_header(worksheet, sheet_name)
                
                # ë°ì´í„° ë³€í™˜ ë° ì—…ë°ì´íŠ¸
                if 'XBRL_ì²˜ë¦¬í˜„í™©' in sheet_name:
                    table_data = self.convert_status_to_table(data)
                elif 'ì£¼ì„' in sheet_name:
                    table_data = self.convert_notes_to_table(data)
                else:
                    table_data = self.convert_xbrl_to_table_format(data)
                
                if table_data:
                    # ê¸°ì¡´ ë°ì´í„° ë³´ì¡´í•˜ë©´ì„œ ìƒˆ ë°ì´í„° ì¶”ê°€
                    self.append_xbrl_data(worksheet, table_data, rcept_no)
                    print(f"âœ… XBRL ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {sheet_name}")
                
            except Exception as sheet_e:
                print(f"âŒ XBRL ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ {sheet_name}: {str(sheet_e)}")
                continue

    def setup_xbrl_sheet_header(self, worksheet, sheet_name):
        """XBRL ì‹œíŠ¸ í—¤ë” ì„¤ì •"""
        if 'XBRL_ì²˜ë¦¬í˜„í™©' in sheet_name:
            headers = ['ì²˜ë¦¬ì¼ì‹œ', 'ì ‘ìˆ˜ë²ˆí˜¸', 'ë³´ê³ ì„œìœ í˜•', 'ì²˜ë¦¬ë°©ì‹', 'ë°ì´í„°ìˆ˜', 'ìƒíƒœ', 'ë¹„ê³ ']
        elif 'ì£¼ì„' in sheet_name:
            headers = ['ì²˜ë¦¬ì¼ì‹œ', 'ì ‘ìˆ˜ë²ˆí˜¸', 'êµ¬ë¶„', 'ì£¼ì„ìœ í˜•', 'ë‚´ìš©', 'í…Œì´ë¸”ìˆ˜', 'ë°ì´í„°ì¶œì²˜', 'ë¹„ê³ ']
        else:
            headers = ['ì²˜ë¦¬ì¼ì‹œ', 'ì ‘ìˆ˜ë²ˆí˜¸', 'êµ¬ë¶„', 'í•­ëª©', 'ë‹¹ê¸°', 'ì „ê¸°', 'ì „ì „ê¸°', 'ë‹¨ìœ„', 'ë°ì´í„°ì¶œì²˜', 'ë¹„ê³ ']
        
        worksheet.update('A1:J1', [headers])
        
        # í—¤ë” ìŠ¤íƒ€ì¼ë§ (ë°°ê²½ìƒ‰ ì„¤ì •)
        try:
            worksheet.format('A1:J1', {
                'backgroundColor': {'red': 0.9, 'green': 0.9, 'blue': 1.0},
                'textFormat': {'bold': True}
            })
        except:
            pass  # ìŠ¤íƒ€ì¼ë§ ì‹¤íŒ¨í•´ë„ ì§„í–‰

    def create_notes_data(self, structured_data, statement_type, rcept_no):
        """ì£¼ì„ ë°ì´í„° ìƒì„±"""
        notes_data = {
            'rcept_no': rcept_no,
            'statement_type': statement_type,  # 'ì—°ê²°' ë˜ëŠ” 'ë³„ë„'
            'processed_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'notes_info': {
                'accounting_policies': 'íšŒê³„ì •ì±… ê´€ë ¨ ì£¼ì„',
                'significant_estimates': 'ì¤‘ìš”í•œ íšŒê³„ì¶”ì • ê´€ë ¨ ì£¼ì„',
                'financial_instruments': 'ê¸ˆìœµìƒí’ˆ ê´€ë ¨ ì£¼ì„',
                'risk_management': 'ìœ„í—˜ê´€ë¦¬ ê´€ë ¨ ì£¼ì„'
            },
            'table_count': 0,  # XBRLì—ì„œ ì¶”ì¶œëœ í…Œì´ë¸” ìˆ˜
            'status': f'XBRL {statement_type} ì£¼ì„ ì²˜ë¦¬ ì™„ë£Œ'
        }
        return notes_data

    def convert_notes_to_table(self, notes_data):
        """ì£¼ì„ ë°ì´í„°ë¥¼ í…Œì´ë¸” í˜•íƒœë¡œ ë³€í™˜"""
        table_data = []
        
        for note_type, content in notes_data['notes_info'].items():
            table_data.append([
                notes_data['statement_type'],
                note_type,
                content,
                str(notes_data['table_count']),
                'XBRL',
                f"{notes_data['statement_type']} ì¬ë¬´ì œí‘œ ì£¼ì„"
            ])
        
        return table_data

    def append_xbrl_data(self, worksheet, table_data, rcept_no):
        """XBRL ë°ì´í„°ë¥¼ ê¸°ì¡´ ì‹œíŠ¸ì— ì¶”ê°€"""
        try:
            # í˜„ì¬ ë°ì´í„° í™•ì¸
            existing_data = worksheet.get_all_values()
            
            # ì¤‘ë³µ ë°ì´í„° í™•ì¸ (ê°™ì€ ì ‘ìˆ˜ë²ˆí˜¸)
            duplicate_rows = []
            for i, row in enumerate(existing_data[1:], 2):  # í—¤ë” ì œì™¸
                if len(row) > 1 and row[1] == rcept_no:  # ì ‘ìˆ˜ë²ˆí˜¸ ì»¬ëŸ¼
                    duplicate_rows.append(i)
            
            if duplicate_rows:
                print(f"âš ï¸ ì¤‘ë³µ ë°ì´í„° ë°œê²¬: {len(duplicate_rows)}í–‰. ì‚­ì œ í›„ ì—…ë°ì´íŠ¸")
                # ì¤‘ë³µ í–‰ ì‚­ì œ (ì—­ìˆœìœ¼ë¡œ)
                for row_num in reversed(duplicate_rows):
                    worksheet.delete_rows(row_num)
            
            # ìƒˆ ë°ì´í„° ì¶”ê°€
            if table_data:
                # ê° í–‰ì— ì²˜ë¦¬ ì •ë³´ ì¶”ê°€
                processed_data = []
                current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                
                for row in table_data:
                    new_row = [current_time, rcept_no] + row
                    processed_data.append(new_row)
                
                worksheet.append_rows(processed_data)
                print(f"ğŸ“ {len(processed_data)}í–‰ ë°ì´í„° ì¶”ê°€ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ XBRL ë°ì´í„° ì¶”ê°€ ì‹¤íŒ¨: {str(e)}")
            raise

    def create_xbrl_status_data(self, structured_data, rcept_no):
        """XBRL ì²˜ë¦¬ í˜„í™© ë°ì´í„° ìƒì„±"""
        status_data = {
            'rcept_no': rcept_no,
            'processed_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'data_counts': {
                'balance_sheet': len(structured_data.get('balance_sheet', {})),
                'income_statement': len(structured_data.get('income_statement', {})),
                'cash_flow': len(structured_data.get('cash_flow', {}))
            },
            'company_info': structured_data.get('company_info', {}),
            'status': 'XBRL ì²˜ë¦¬ ì™„ë£Œ'
        }
        return status_data

    def convert_status_to_table(self, status_data):
        """ì²˜ë¦¬ í˜„í™©ì„ í…Œì´ë¸” í˜•íƒœë¡œ ë³€í™˜"""
        table_data = []
        
        total_count = sum(status_data['data_counts'].values())
        
        table_data.append([
            status_data['processed_time'],
            status_data['rcept_no'],
            'ë¶„ê¸°ë³´ê³ ì„œ',
            'XBRL',
            str(total_count),
            status_data['status'],
            f"ì¬ë¬´ìƒíƒœí‘œ:{status_data['data_counts']['balance_sheet']}, ì†ìµê³„ì‚°ì„œ:{status_data['data_counts']['income_statement']}"
        ])
        
        return table_data

    def convert_xbrl_to_table_format(self, structured_data):
        """XBRL êµ¬ì¡°í™” ë°ì´í„°ë¥¼ í…Œì´ë¸” í˜•íƒœë¡œ ë³€í™˜"""
        table_data = []
        
        # ì¬ë¬´ìƒíƒœí‘œ ë°ì´í„°
        if structured_data.get('balance_sheet'):
            for item, value in structured_data['balance_sheet'].items():
                table_data.append([
                    'ì¬ë¬´ìƒíƒœí‘œ', item, str(value), '', '', 'KRW', 'XBRL', ''
                ])
        
        # ì†ìµê³„ì‚°ì„œ ë°ì´í„°
        if structured_data.get('income_statement'):
            for item, value in structured_data['income_statement'].items():
                table_data.append([
                    'ì†ìµê³„ì‚°ì„œ', item, str(value), '', '', 'KRW', 'XBRL', ''
                ])
        
        # í˜„ê¸ˆíë¦„í‘œ ë°ì´í„°
        if structured_data.get('cash_flow'):
            for item, value in structured_data['cash_flow'].items():
                table_data.append([
                    'í˜„ê¸ˆíë¦„í‘œ', item, str(value), '', '', 'KRW', 'XBRL', ''
                ])
        
        return table_data

    def update_html_worksheet(self, sheet_name, url):
        """HTML ë°©ì‹ ì›Œí¬ì‹œíŠ¸ ì—…ë°ì´íŠ¸ (ê¸°ì¡´ ë°©ì‹)"""
        try:
            # HTML ì‹œíŠ¸ëŠ” ê¸°ì¡´ ë°©ì‹ ìœ ì§€
            try:
                worksheet = self.workbook.worksheet(sheet_name)
            except gspread.exceptions.WorksheetNotFound:
                worksheet = self.workbook.add_worksheet(sheet_name, 1000, 10)
            
            print(f"ğŸŒ HTML ë°ì´í„° ë‹¤ìš´ë¡œë“œ: {url}")
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            
            if response.status_code == 200:
                print(f"ğŸ“Š HTML ì½˜í…ì¸  ì²˜ë¦¬...")
                self.process_html_content(worksheet, response.text, sheet_name)
                print(f"âœ… HTML ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {sheet_name}")
            else:
                raise Exception(f"HTTP ì˜¤ë¥˜: {response.status_code}")
                
        except Exception as e:
            print(f"âŒ HTML ì›Œí¬ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
            raise

    def process_html_content(self, worksheet, html_content, sheet_name):
        """HTML ë‚´ìš© ì²˜ë¦¬ (ê°œì„ ëœ ë²„ì „)"""
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            tables = soup.find_all("table")
            
            # ê¸°ì¡´ ë°ì´í„° ë°±ì—… ë° í´ë¦¬ì–´
            worksheet.clear()
            
            # ì‹œíŠ¸ ë©”íƒ€ë°ì´í„° ì¶”ê°€
            metadata = [
                [f'HTML ì²˜ë¦¬ ì‹œíŠ¸: {sheet_name}'],
                [f'ì²˜ë¦¬ ì¼ì‹œ: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}'],
                [f'ë°ì´í„° ì¶œì²˜: HTML ìŠ¤í¬ë˜í•‘'],
                ['']  # ë¹ˆ í–‰
            ]
            
            all_data = metadata.copy()
            
            print(f"ë°œê²¬ëœ í…Œì´ë¸” ìˆ˜: {len(tables)}")
            
            for i, table in enumerate(tables):
                table_data = self.parse_html_table_robust(table)
                
                if table_data:
                    print(f"í…Œì´ë¸” {i+1}: {len(table_data)}í–‰ ì¶”ì¶œ")
                    all_data.extend(table_data)
                    all_data.append([''])  # í…Œì´ë¸” ê°„ êµ¬ë¶„
            
            if len(all_data) > len(metadata):
                # ë§ˆì§€ë§‰ ë¹ˆ í–‰ ì œê±°
                if all_data and all_data[-1] == ['']:
                    all_data.pop()
                
                print(f"ì „ì²´ {len(all_data)}í–‰ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
                
                # ë°°ì¹˜ ì—…ë¡œë“œ
                BATCH_SIZE = 100
                for i in range(0, len(all_data), BATCH_SIZE):
                    batch = all_data[i:i + BATCH_SIZE]
                    
                    # í–‰ ê¸¸ì´ ì •ê·œí™”
                    max_cols = max(len(row) for row in batch) if batch else 0
                    normalized_batch = []
                    for row in batch:
                        normalized_row = row + [''] * (max_cols - len(row))
                        normalized_batch.append(normalized_row)
                    
                    try:
                        worksheet.append_rows(normalized_batch)
                        print(f"ë°°ì¹˜ ì—…ë¡œë“œ: {i+1}~{min(i+BATCH_SIZE, len(all_data))} í–‰")
                        
                    except gspread.exceptions.APIError as e:
                        if 'Quota exceeded' in str(e):
                            print("API í• ë‹¹ëŸ‰ ì´ˆê³¼. 60ì´ˆ ëŒ€ê¸°...")
                            time.sleep(60)
                            worksheet.append_rows(normalized_batch)
                        else:
                            raise e
            else:
                print("âš ï¸ ì¶”ì¶œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            print(f"âŒ HTML ì½˜í…ì¸  ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            raise

    def parse_html_table_robust(self, table):
        """ê²¬ê³ í•œ HTML í…Œì´ë¸” íŒŒì‹±"""
        try:
            if HTML_PARSER_AVAILABLE:
                try:
                    return parser.make2d(table)
                except Exception:
                    pass
            
            # ë‚´ì¥ íŒŒì„œ ì‚¬ìš©
            rows = []
            for tr in table.find_all('tr'):
                row = []
                for cell in tr.find_all(['td', 'th']):
                    text = cell.get_text(separator=' ', strip=True)
                    text = re.sub(r'\s+', ' ', text)
                    row.append(text)
                
                if row:
                    rows.append(row)
            
            return rows
            
        except Exception as e:
            print(f"HTML í…Œì´ë¸” íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
            return []

    def record_processing_result(self, report, xbrl_success, html_success):
        """ì²˜ë¦¬ ê²°ê³¼ ê¸°ë¡"""
        result_status = ""
        if xbrl_success and html_success:
            result_status = "âœ… XBRL+HTML ëª¨ë‘ ì„±ê³µ"
        elif xbrl_success:
            result_status = "ğŸ”¬ XBRLë§Œ ì„±ê³µ"
        elif html_success:
            result_status = "ğŸŒ HTMLë§Œ ì„±ê³µ"
        else:
            result_status = "âŒ ëª¨ë‘ ì‹¤íŒ¨"
        
        print(f"ğŸ“‹ ì²˜ë¦¬ ê²°ê³¼: {report['report_nm']} - {result_status}")

    def print_processing_summary(self):
        """ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print(f"\nğŸ“Š === ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ ===")
        print(f"ì „ì²´ ë³´ê³ ì„œ ìˆ˜: {self.processing_results['total_processed']}")
        print(f"XBRL Excel ì„±ê³µ: {len(self.processing_results['xbrl_xlsx_success'])}ê°œ")
        print(f"XBRL Excel ì‹¤íŒ¨: {len(self.processing_results['xbrl_xlsx_failed'])}ê°œ")
        print(f"XBRL ì„±ê³µ: {len(self.processing_results['xbrl_success'])}ê°œ")
        print(f"XBRL ì‹¤íŒ¨: {len(self.processing_results['xbrl_failed'])}ê°œ")
        print(f"HTML ì„±ê³µ: {len(self.processing_results['html_success'])}ê°œ")
        print(f"HTML ì‹¤íŒ¨: {len(self.processing_results['html_failed'])}ê°œ")
        
        # í…”ë ˆê·¸ë¨ ìš”ì•½ ë©”ì‹œì§€
        summary_message = (
            f"ğŸ”„ DART ì´ì›í™” ì²˜ë¦¬ ì™„ë£Œ\n\n"
            f"â€¢ ì¢…ëª©: {self.company_name} ({self.corp_code})\n"
            f"â€¢ ì²˜ë¦¬ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
            f"â€¢ ì „ì²´ ë³´ê³ ì„œ: {self.processing_results['total_processed']}ê°œ\n"
            f"â€¢ XBRL Excel ì„±ê³µ: {len(self.processing_results['xbrl_xlsx_success'])}ê°œ\n"
            f"â€¢ XBRL ì„±ê³µ: {len(self.processing_results['xbrl_success'])}ê°œ\n"
            f"â€¢ HTML ì„±ê³µ: {len(self.processing_results['html_success'])}ê°œ\n"
            f"â€¢ ì´ ì‹œíŠ¸ ìƒì„±: {len(self.processing_results['xbrl_xlsx_success']) + len(self.processing_results['xbrl_success']) + len(self.processing_results['html_success'])}ê°œ"
        )
        self.send_telegram_message(summary_message)

    # XBRL ê´€ë ¨ ë©”ì†Œë“œë“¤ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
    def download_xbrl_data(self, rcept_no):
        """XBRL ë°ì´í„° ë‹¤ìš´ë¡œë“œ"""
        print(f"XBRL ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹œì‘: {rcept_no}")
        
        try:
            download_url = f"https://opendart.fss.or.kr/disclosureinfo/fnltt/dwld/main.do?rcp_no={rcept_no}"
            
            session = requests.Session()
            session.headers.update({
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': 'application/zip, application/xml, text/xml, */*',
                'Referer': 'https://opendart.fss.or.kr/'
            })
            
            response = session.get(download_url, timeout=30)
            response.raise_for_status()
            
            content_type = response.headers.get('content-type', '').lower()
            content_disposition = response.headers.get('content-disposition', '').lower()
            
            if ('application/zip' in content_type or 
                'application/x-zip' in content_type or 
                '.zip' in content_disposition):
                print("ZIP íŒŒì¼ ê°ì§€, ì••ì¶• í•´ì œ ì¤‘...")
                return self.extract_xbrl_from_zip(response.content)
            
            elif ('xml' in content_type or 
                  response.content.strip().startswith(b'<?xml')):
                print("XML íŒŒì¼ ê°ì§€")
                return response.content.decode('utf-8')
            
            else:
                print(f"ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼ í˜•ì‹: {content_type}")
                raise ValueError("XBRL íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            print(f"XBRL ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise

    def extract_xbrl_from_zip(self, zip_content):
        """ZIP íŒŒì¼ì—ì„œ XBRL ë°ì´í„° ì¶”ì¶œ"""
        try:
            with zipfile.ZipFile(io.BytesIO(zip_content)) as zip_ref:
                file_list = zip_ref.namelist()
                print(f"ZIP íŒŒì¼ ë‚´ìš©: {file_list}")
                
                xbrl_patterns = [
                    r'.*\.xbrl$',
                    r'.*xbrl.*\.xml$',
                    r'.*_financial.*\.xml$',
                    r'.*\.xml$'
                ]
                
                xbrl_file = None
                for pattern in xbrl_patterns:
                    matching_files = [f for f in file_list if re.match(pattern, f, re.IGNORECASE)]
                    if matching_files:
                        xbrl_file = max(matching_files, key=lambda x: zip_ref.getinfo(x).file_size)
                        print(f"XBRL íŒŒì¼ ì„ íƒ: {xbrl_file}")
                        break
                
                if xbrl_file:
                    with zip_ref.open(xbrl_file) as f:
                        content = f.read()
                        try:
                            return content.decode('utf-8')
                        except UnicodeDecodeError:
                            try:
                                return content.decode('utf-8-sig')
                            except UnicodeDecodeError:
                                return content.decode('euc-kr')
                else:
                    raise ValueError("ZIP íŒŒì¼ì—ì„œ XBRL íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    
        except Exception as e:
            print(f"ZIP íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            raise

    def parse_xbrl_data(self, xbrl_content):
        """XBRL XML ë°ì´í„° íŒŒì‹±"""
        try:
            print("XBRL ë°ì´í„° íŒŒì‹± ì‹œì‘...")
            root = ET.fromstring(xbrl_content)
            print("XML íŒŒì‹± ì„±ê³µ")
            
            for prefix, uri in root.attrib.items():
                if prefix.startswith('xmlns:'):
                    ns_prefix = prefix[6:]
                    self.xbrl_namespaces[ns_prefix] = uri
                elif prefix == 'xmlns':
                    self.xbrl_namespaces['default'] = uri
            
            parsed_data = {
                'contexts': self.extract_contexts(root),
                'financial_data': self.extract_financial_data(root),
                'company_info': self.extract_company_info(root),
                'metadata': self.extract_metadata(root)
            }
            
            print("XBRL ë°ì´í„° íŒŒì‹± ì™„ë£Œ")
            return parsed_data
            
        except Exception as e:
            print(f"XBRL ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
            raise

    def extract_contexts(self, root):
        """Context ì •ë³´ ì¶”ì¶œ"""
        contexts = {}
        context_elements = root.findall('.//xbrl:context', self.xbrl_namespaces)
        
        for context in context_elements:
            context_id = context.get('id')
            
            period_info = {}
            period = context.find('xbrl:period', self.xbrl_namespaces)
            if period is not None:
                instant = period.find('xbrl:instant', self.xbrl_namespaces)
                start_date = period.find('xbrl:startDate', self.xbrl_namespaces)
                end_date = period.find('xbrl:endDate', self.xbrl_namespaces)
                
                if instant is not None:
                    period_info['type'] = 'instant'
                    period_info['date'] = instant.text
                elif start_date is not None and end_date is not None:
                    period_info['type'] = 'duration'
                    period_info['start_date'] = start_date.text
                    period_info['end_date'] = end_date.text
            
            contexts[context_id] = {'period': period_info}
        
        return contexts

    def extract_financial_data(self, root):
        """ì¬ë¬´ ë°ì´í„° ì¶”ì¶œ"""
        financial_data = {}
        
        key_items = {
            'Assets': ['ifrs-full:Assets', 'dart:Assets'],
            'Liabilities': ['ifrs-full:Liabilities', 'dart:Liabilities'],
            'Equity': ['ifrs-full:Equity', 'dart:Equity'],
            'Revenue': ['ifrs-full:Revenue', 'dart:Revenue'],
            'ProfitLoss': ['ifrs-full:ProfitLoss', 'dart:ProfitLoss']
        }
        
        for item_name, possible_tags in key_items.items():
            for tag in possible_tags:
                elements = root.findall(f'.//{tag}', self.xbrl_namespaces)
                if elements:
                    item_data = []
                    for elem in elements:
                        item_data.append({
                            'value': elem.text,
                            'context_ref': elem.get('contextRef'),
                            'unit_ref': elem.get('unitRef'),
                            'decimals': elem.get('decimals')
                        })
                    financial_data[item_name] = item_data
                    break
        
        return financial_data

    def extract_company_info(self, root):
        """íšŒì‚¬ ì •ë³´ ì¶”ì¶œ"""
        return {}

    def extract_metadata(self, root):
        """ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        return {}

    def convert_xbrl_to_structured_data(self, parsed_xbrl):
        """XBRL ë°ì´í„°ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë³€í™˜"""
        structured_data = {
            'balance_sheet': {},
            'income_statement': {},
            'cash_flow': {},
            'company_info': parsed_xbrl.get('company_info', {}),
            'reporting_period': None
        }
        
        financial_mapping = {
            'balance_sheet': {
                'Assets': 'ìì‚°ì´ê³„',
                'Liabilities': 'ë¶€ì±„ì´ê³„',
                'Equity': 'ìë³¸ì´ê³„'
            },
            'income_statement': {
                'Revenue': 'ë§¤ì¶œì•¡',
                'ProfitLoss': 'ë‹¹ê¸°ìˆœì´ìµ'
            }
        }
        
        financial_data = parsed_xbrl.get('financial_data', {})
        
        for statement_type, mapping in financial_mapping.items():
            for xbrl_item, korean_name in mapping.items():
                if xbrl_item in financial_data and financial_data[xbrl_item]:
                    item_data = financial_data[xbrl_item][0]
                    value = item_data['value']
                    
                    if value:
                        try:
                            cleaned_value = re.sub(r'[,\s]', '', value)
                            numeric_value = float(cleaned_value)
                            structured_data[statement_type][korean_name] = numeric_value
                        except ValueError:
                            structured_data[statement_type][korean_name] = value
        
        return structured_data

    # ê¸°ì¡´ ìœ í‹¸ë¦¬í‹° ë©”ì†Œë“œë“¤
    def get_recent_dates(self):
        """ë‚ ì§œ ë²”ìœ„ ê³„ì‚° (ìˆ˜ë™ ì„¤ì • ë˜ëŠ” ê¸°ë³¸ 3ê°œì›”)"""
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ë‚ ì§œ ë²”ìœ„ í™•ì¸
        manual_start = os.environ.get('MANUAL_START_DATE')
        manual_end = os.environ.get('MANUAL_END_DATE')
        
        if manual_start and manual_end:
            try:
                # ë‚ ì§œ í˜•ì‹ ê²€ì¦
                start_date = datetime.strptime(manual_start, '%Y%m%d')
                end_date = datetime.strptime(manual_end, '%Y%m%d')
                
                # ë‚ ì§œ ë²”ìœ„ ê²€ì¦
                if start_date > end_date:
                    print("âš ï¸ ì‹œì‘ì¼ì´ ì¢…ë£Œì¼ë³´ë‹¤ ëŠ¦ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë²”ìœ„ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                    return self.get_default_date_range()
                
                # ë„ˆë¬´ ê¸´ ê¸°ê°„ ì œí•œ (ìµœëŒ€ 2ë…„)
                if (end_date - start_date).days > 730:
                    print("âš ï¸ ë‚ ì§œ ë²”ìœ„ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤ (ìµœëŒ€ 2ë…„). ê¸°ë³¸ ë²”ìœ„ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                    return self.get_default_date_range()
                
                print(f"ğŸ“… ìˆ˜ë™ ì„¤ì • ë‚ ì§œ ë²”ìœ„: {manual_start} ~ {manual_end}")
                print(f"ğŸ“… ê¸°ê°„: {(end_date - start_date).days + 1}ì¼")
                
                return manual_start, manual_end
                
            except ValueError as e:
                print(f"âš ï¸ ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜: {str(e)}. ê¸°ë³¸ ë²”ìœ„ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                return self.get_default_date_range()
        else:
            return self.get_default_date_range()
    
    def get_default_date_range(self):
        """ê¸°ë³¸ 3ê°œì›” ë‚ ì§œ ë²”ìœ„"""
        end_date = datetime.now()
        start_date = end_date - timedelta(days=90)
        date_range = start_date.strftime('%Y%m%d'), end_date.strftime('%Y%m%d')
        print(f"ğŸ“… ê¸°ë³¸ ë‚ ì§œ ë²”ìœ„ (ìµœê·¼ 3ê°œì›”): {date_range[0]} ~ {date_range[1]}")
        return date_range

    def get_column_letter(self, col_num):
        """ìˆ«ìë¥¼ ì—‘ì…€ ì—´ ë¬¸ìë¡œ ë³€í™˜"""
        result = ""
        while col_num > 0:
            col_num, remainder = divmod(col_num - 1, 26)
            result = chr(65 + remainder) + result
        return result

    def send_telegram_message(self, message):
        """í…”ë ˆê·¸ë¨ìœ¼ë¡œ ë©”ì‹œì§€ ì „ì†¡"""
        if not self.telegram_bot_token or not self.telegram_channel_id:
            print("ğŸ“± í…”ë ˆê·¸ë¨ ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        try:
            url = f"https://api.telegram.org/bot{self.telegram_bot_token}/sendMessage"
            data = {
                "chat_id": self.telegram_channel_id,
                "text": message,
                "parse_mode": "HTML"
            }
            response = requests.post(url, data=data)
            response.raise_for_status()
            print("ğŸ“± í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì „ì†¡ ì™„ë£Œ")
        except Exception as e:
            print(f"ğŸ“± í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨: {str(e)}")

    def remove_parentheses(self, value):
        """ê´„í˜¸ ë‚´ìš© ì œê±°"""
        if not value:
            return value
        return re.sub(r'\s*\(.*?\)\s*', '', value).replace('%', '')

    def process_archive_data(self, archive, start_row, last_col):
        """ì•„ì¹´ì´ë¸Œ ë°ì´í„° ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)"""
        try:
            print(f"ğŸ“Š Archive ë°ì´í„° ì²˜ë¦¬ ì‹œì‘: í–‰={start_row}, ì—´={last_col}")
            
            current_cols = archive.col_count
            target_col_letter = self.get_column_letter(last_col)
            
            if last_col >= current_cols:
                new_cols = last_col + 5
                print(f"ğŸ”§ ì‹œíŠ¸ í¬ê¸° ì¡°ì •: {current_cols} â†’ {new_cols}")
                archive.resize(rows=archive.row_count, cols=new_cols)
                time.sleep(2)

            all_rows = archive.get_all_values()
            update_data = []
            sheet_cache = {}
            
            sheet_rows = {}
            processed_count = 0
            
            for row_idx in range(start_row - 1, len(all_rows)):
                if len(all_rows[row_idx]) < 5:
                    continue
                    
                sheet_name = all_rows[row_idx][0]
                if not sheet_name:
                    continue
                
                if sheet_name not in sheet_rows:
                    sheet_rows[sheet_name] = []
                    
                sheet_rows[sheet_name].append({
                    'row_idx': row_idx + 1,
                    'keyword': all_rows[row_idx][1],
                    'n': all_rows[row_idx][2],
                    'x': all_rows[row_idx][3],
                    'y': all_rows[row_idx][4]
                })
                processed_count += 1
            
            print(f"ğŸ“‹ ì²˜ë¦¬í•  ì‹œíŠ¸ ìˆ˜: {len(sheet_rows)}, ì´ í–‰ ìˆ˜: {processed_count}")
            
            for sheet_name, rows in sheet_rows.items():
                try:
                    print(f"\nğŸ” ì‹œíŠ¸ '{sheet_name}' ì²˜ë¦¬ ì¤‘ (í•­ëª©: {len(rows)}ê°œ)")
                    
                    if sheet_name not in sheet_cache:
                        try:
                            search_sheet = self.workbook.worksheet(sheet_name)
                            sheet_data = search_sheet.get_all_values()
                            df = pd.DataFrame(sheet_data)
                            sheet_cache[sheet_name] = df
                            print(f"âœ… ì‹œíŠ¸ ë°ì´í„° ë¡œë“œ: {df.shape}")
                        except gspread.exceptions.WorksheetNotFound:
                            print(f"âš ï¸ ì‹œíŠ¸ '{sheet_name}' ì—†ìŒ. ê±´ë„ˆëœ€.")
                            continue
                    
                    df = sheet_cache[sheet_name]
                    
                    for row in rows:
                        try:
                            keyword = row['keyword']
                            if not all([keyword, row['n'], row['x'], row['y']]):
                                continue
                            
                            n, x, y = int(row['n']), int(row['x']), int(row['y'])
                            
                            keyword_positions = []
                            for idx, df_row in df.iterrows():
                                for col_idx, value in enumerate(df_row):
                                    if str(value).strip() == keyword.strip():
                                        keyword_positions.append((idx, col_idx))
                            
                            if keyword_positions and len(keyword_positions) >= n:
                                target_pos = keyword_positions[n - 1]
                                target_row = target_pos[0] + y
                                target_col = target_pos[1] + x
                                
                                if (0 <= target_row < df.shape[0] and 
                                    0 <= target_col < df.shape[1]):
                                    value = df.iat[target_row, target_col]
                                    cleaned_value = self.remove_parentheses(str(value))
                                    update_data.append((row['row_idx'], cleaned_value))
                                    print(f"âœ… ê°’ ë°œê²¬: {keyword} â†’ {cleaned_value}")
                                else:
                                    print(f"âš ï¸ ë²”ìœ„ ì´ˆê³¼: {keyword}")
                            else:
                                print(f"âš ï¸ í‚¤ì›Œë“œ ë¯¸ë°œê²¬: {keyword}")
                                
                        except Exception as row_e:
                            print(f"âŒ í–‰ ì²˜ë¦¬ ì˜¤ë¥˜: {str(row_e)}")
                            continue
                
                except Exception as sheet_e:
                    print(f"âŒ ì‹œíŠ¸ '{sheet_name}' ì²˜ë¦¬ ì˜¤ë¥˜: {str(sheet_e)}")
                    continue
            
            print(f"\nğŸ“Š ì—…ë°ì´íŠ¸í•  ë°ì´í„°: {len(update_data)}ê°œ")
            
            if update_data:
                self.update_archive_column(archive, update_data, target_col_letter, last_col)
                
                today = datetime.now()
                three_months_ago = today - timedelta(days=90)
                year = str(three_months_ago.year)[2:]
                quarter = (three_months_ago.month - 1) // 3 + 1
                quarter_text = f"{quarter}Q{year}"
                
                meta_updates = [
                    {'range': 'J1', 'values': [[today.strftime('%Y-%m-%d')]]},
                    {'range': f'{target_col_letter}1', 'values': [['1']]},
                    {'range': f'{target_col_letter}5', 'values': [[today.strftime('%Y-%m-%d')]]},
                    {'range': f'{target_col_letter}6', 'values': [[quarter_text]]}
                ]
                
                archive.batch_update(meta_updates)
                print(f"âœ… ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ (ë¶„ê¸°: {quarter_text})")
                
                message = (
                    f"ğŸ”„ DART Archive ì—…ë°ì´íŠ¸ ì™„ë£Œ\n\n"
                    f"â€¢ ì¢…ëª©: {self.company_name} ({self.corp_code})\n"
                    f"â€¢ ë¶„ê¸°: {quarter_text}\n"
                    f"â€¢ ì—…ë°ì´íŠ¸ ì¼ì‹œ: {today.strftime('%Y-%m-%d %H:%M:%S')}\n"
                    f"â€¢ ì²˜ë¦¬ëœ í–‰: {len(update_data)}ê°œ\n"
                    f"â€¢ ì‹œíŠ¸ ì—´: {target_col_letter} (#{last_col})"
                )
                self.send_telegram_message(message)
                
            else:
                print("âš ï¸ ì—…ë°ì´íŠ¸í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            error_msg = f"Archive ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"
            print(f"âŒ {error_msg}")
            self.send_telegram_message(f"âŒ {error_msg}")
            raise

    def update_archive_column(self, archive, update_data, target_col_letter, last_col):
        """Archive ì—´ ë°ì´í„° ì—…ë°ì´íŠ¸"""
        try:
            min_row = min(row for row, _ in update_data)
            max_row = max(row for row, _ in update_data)
            
            column_data = [''] * (max_row - min_row + 1)
            for row, value in update_data:
                adjusted_row = row - min_row
                column_data[adjusted_row] = value
            
            column_data_2d = [[value] for value in column_data]
            
            range_label = f'{target_col_letter}{min_row}:{target_col_letter}{max_row}'
            print(f"ğŸ“ ì—…ë°ì´íŠ¸ ë²”ìœ„: {range_label}")
            
            archive.batch_update([{
                'range': range_label,
                'values': column_data_2d
            }])
            
            print(f"âœ… ì»¬ëŸ¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {min_row}~{max_row} í–‰")
            
        except Exception as e:
            print(f"âŒ ì»¬ëŸ¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
            raise


def load_company_config():
    """yml íŒŒì¼ì—ì„œ íšŒì‚¬ ì„¤ì • ë¡œë“œ ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ ì½ê¸°"""
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì½ê¸° (GitHub Actions ì‚¬ìš©)
    corp_code = os.environ.get('COMPANY_CORP_CODE')
    company_name = os.environ.get('COMPANY_NAME')
    spreadsheet_var = os.environ.get('COMPANY_SPREADSHEET_VAR')
    
    if corp_code and company_name and spreadsheet_var:
        return {
            'corp_code': corp_code,
            'company_name': company_name,
            'spreadsheet_var': spreadsheet_var
        }
    
    # ê¸°ë³¸ê°’ (ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©)
    return {
        'corp_code': '307950',
        'company_name': 'í˜„ëŒ€ì˜¤í† ì—ë²„',
        'spreadsheet_var': 'AUTOEVER_SPREADSHEET_ID'
    }


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        import sys
        
        def log(msg):
            print(f"ğŸ¤– {msg}")
            sys.stdout.flush()
        
        # yml ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ë¡œë“œ
        company_config = load_company_config()
        
        log(f"{company_config['company_name']}({company_config['corp_code']}) ì´ì›í™” ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸ ì‹œì‘")
        
        try:
            updater = DualSystemDartUpdater(company_config)
            
            # ì´ì›í™” ì‹œìŠ¤í…œìœ¼ë¡œ ë³´ê³ ì„œ ì—…ë°ì´íŠ¸
            log("ğŸ“‹ ì´ì›í™” DART ë³´ê³ ì„œ ì—…ë°ì´íŠ¸ ì‹œì‘...")
            updater.update_dart_reports()
            log("âœ… ì´ì›í™” DART ë³´ê³ ì„œ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            
            # Archive ì‹œíŠ¸ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
            log("ğŸ“Š Archive ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì‹œì‘...")
            archive = updater.workbook.worksheet('Dart_Archive')
            
            sheet_values = archive.get_all_values()
            if not sheet_values:
                raise ValueError("Dart_Archive ì‹œíŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            
            last_col = len(sheet_values[0])
            control_value = archive.cell(1, last_col).value
            start_row = 10
            
            if control_value:
                last_col += 1
            
            log(f"Archive ì²˜ë¦¬: ì‹œì‘í–‰={start_row}, ëŒ€ìƒì—´={last_col}")
            updater.process_archive_data(archive, start_row, last_col)
            log("âœ… Archive ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            
            log("ğŸ‰ ì´ì›í™” ì‹œìŠ¤í…œ ì „ì²´ ì‘ì—… ì™„ë£Œ!")
            
        except Exception as e:
            log(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            if 'updater' in locals():
                updater.send_telegram_message(
                    f"âŒ ì´ì›í™” DART ì—…ë°ì´íŠ¸ ì‹¤íŒ¨\n\n"
                    f"â€¢ ì¢…ëª©: {company_config['company_name']} ({company_config['corp_code']})\n"
                    f"â€¢ ì˜¤ë¥˜: {str(e)}"
                )
            raise

    except Exception as e:
        print(f"ğŸ’¥ ì „ì²´ ì‘ì—… ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {str(e)}")
        print(f"ğŸ” ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
        raise e

if __name__ == "__main__":
    main()
