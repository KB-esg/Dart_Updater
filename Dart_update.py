import os
from datetime import datetime, timedelta
import json
import time
import re
import gspread
from google.oauth2.service_account import Credentials
import OpenDartReader
import requests
from bs4 import BeautifulSoup
from html_table_parser import parser_functions as parser
import pandas as pd
from openpyxl import load_workbook
from playwright.sync_api import sync_playwright
import shutil
from tqdm import tqdm

class DartDualUpdater:
    """DART XBRL Excel ë‹¤ìš´ë¡œë“œ + HTML ìŠ¤í¬ë˜í•‘ í†µí•© ì‹œìŠ¤í…œ"""
    
    # HTML ìŠ¤í¬ë˜í•‘ ëŒ€ìƒ ì‹œíŠ¸ (ì¬ë¬´ì œí‘œ ê´€ë ¨ ì œì™¸)
    HTML_TARGET_SHEETS = [
        'I. íšŒì‚¬ì˜ ê°œìš”', 'II. ì‚¬ì—…ì˜ ë‚´ìš©', '1. ì‚¬ì—…ì˜ ê°œìš”', '2. ì£¼ìš” ì œí’ˆ ë° ì„œë¹„ìŠ¤',
        '3. ì›ì¬ë£Œ ë° ìƒì‚°ì„¤ë¹„', '4. ë§¤ì¶œ ë° ìˆ˜ì£¼ìƒí™©', '5. ìœ„í—˜ê´€ë¦¬ ë° íŒŒìƒê±°ë˜',
        '6. ì£¼ìš”ê³„ì•½ ë° ì—°êµ¬í™œë™', '7. ê¸°íƒ€ ì°¸ê³  ì‚¬í•­', '1. ìš”ì•½ì¬ë¬´ì •ë³´',
        # ì¬ë¬´ì œí‘œ ê´€ë ¨ ì‹œíŠ¸ ì œì™¸ (XBRLì—ì„œ ì²˜ë¦¬)
        # '2. ì—°ê²°ì¬ë¬´ì œí‘œ', '3. ì—°ê²°ì¬ë¬´ì œí‘œ ì£¼ì„', '4. ì¬ë¬´ì œí‘œ', '5. ì¬ë¬´ì œí‘œ ì£¼ì„',
        '6. ë°°ë‹¹ì— ê´€í•œ ì‚¬í•­', '8. ê¸°íƒ€ ì¬ë¬´ì— ê´€í•œ ì‚¬í•­', 'VII. ì£¼ì£¼ì— ê´€í•œ ì‚¬í•­',
        'VIII. ì„ì› ë° ì§ì› ë“±ì— ê´€í•œ ì‚¬í•­', 'X. ëŒ€ì£¼ì£¼ ë“±ê³¼ì˜ ê±°ë˜ë‚´ìš©',
        'XI. ê·¸ ë°–ì— íˆ¬ìì ë³´í˜¸ë¥¼ ìœ„í•˜ì—¬ í•„ìš”í•œ ì‚¬í•­'
    ]
    
    def __init__(self, company_config):
        """ì´ˆê¸°í™”"""
        self.corp_code = company_config['corp_code']
        self.company_name = company_config['company_name']
        self.spreadsheet_var_name = company_config['spreadsheet_var']
        
        # í™˜ê²½ë³€ìˆ˜ í™•ì¸
        self._check_environment_variables()
        
        # Google Sheets ì„¤ì •
        self.credentials = self._get_google_credentials()
        self.gc = gspread.authorize(self.credentials)
        self.workbook = self.gc.open_by_key(os.environ[self.spreadsheet_var_name])
        
        # DART API ì„¤ì •
        self.dart = OpenDartReader(os.environ['DART_API_KEY'])
        
        # í…”ë ˆê·¸ë¨ ì„¤ì •
        self.telegram_bot_token = os.environ.get('TELEGRAM_BOT_TOKEN')
        self.telegram_channel_id = os.environ.get('TELEGRAM_CHANNEL_ID')
        
        # ë‹¤ìš´ë¡œë“œ í´ë” ì„¤ì • (XBRLìš©)
        self.download_dir = os.path.join(os.getcwd(), 'downloads')
        os.makedirs(self.download_dir, exist_ok=True)
        
        # ì²˜ë¦¬ ê²°ê³¼ ì¶”ì 
        self.results = {
            'total_reports': 0,
            'xbrl': {
                'downloaded_files': [],
                'uploaded_sheets': [],
                'failed_downloads': [],
                'failed_uploads': [],
                'excel_files': {}
            },
            'html': {
                'processed_sheets': [],
                'failed_sheets': []
            }
        }
        
        # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ë³´ê³ ì„œ ì •ë³´
        self.current_report = None
        
        # Archive ì‹œíŠ¸ í–‰ ì˜ì—­ ë§¤í•‘ ì„¤ì •
        self._setup_archive_row_mapping()

    def _check_environment_variables(self):
        """í™˜ê²½ë³€ìˆ˜ í™•ì¸"""
        print("ğŸ” í™˜ê²½ë³€ìˆ˜ í™•ì¸:")
        required_vars = ['DART_API_KEY', 'GOOGLE_CREDENTIALS', self.spreadsheet_var_name]
        
        for var in required_vars:
            if var in os.environ:
                value = os.environ[var]
                masked_value = f"{value[:6]}...{value[-4:]}" if len(value) > 20 else f"{value[:-2]}**"
                print(f"âœ… {var}: {masked_value} (ê¸¸ì´: {len(value)})")
            else:
                raise ValueError(f"âŒ {var} í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    def _get_google_credentials(self):
        """Google Sheets ì¸ì¦ ì„¤ì •"""
        creds_json = json.loads(os.environ['GOOGLE_CREDENTIALS'])
        scopes = [
            'https://www.googleapis.com/auth/spreadsheets',
            'https://www.googleapis.com/auth/drive'
        ]
        return Credentials.from_service_account_info(creds_json, scopes=scopes)

    def _setup_archive_row_mapping(self):
        """Archive ì‹œíŠ¸ì˜ í–‰ ì˜ì—­ ë§¤í•‘ ì„¤ì •"""
        # ì¬ë¬´ì œí‘œ Archive ì‹œíŠ¸ í–‰ ë§¤í•‘
        self.financial_row_mapping = {
            'consolidated': {
                'D210000': {'start': 7, 'end': 80, 'name': 'ì—°ê²° ì¬ë¬´ìƒíƒœí‘œ'},
                'D431410': {'start': 81, 'end': 140, 'name': 'ì—°ê²° ì†ìµê³„ì‚°ì„œ'},
                'D520000': {'start': 141, 'end': 200, 'name': 'ì—°ê²° í˜„ê¸ˆíë¦„í‘œ'},
                'D610000': {'start': 201, 'end': 250, 'name': 'ì—°ê²° ìë³¸ë³€ë™í‘œ'}
            },
            'standalone': {
                'D210005': {'start': 257, 'end': 330, 'name': 'ë³„ë„ ì¬ë¬´ìƒíƒœí‘œ'},
                'D431415': {'start': 331, 'end': 390, 'name': 'ë³„ë„ ì†ìµê³„ì‚°ì„œ'},
                'D520005': {'start': 391, 'end': 450, 'name': 'ë³„ë„ í˜„ê¸ˆíë¦„í‘œ'},
                'D610005': {'start': 451, 'end': 500, 'name': 'ë³„ë„ ìë³¸ë³€ë™í‘œ'}
            }
        }

    def run(self):
        """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (XBRL + HTML í†µí•©)"""
        print(f"\nğŸš€ {self.company_name}({self.corp_code}) DART í†µí•© ì—…ë°ì´íŠ¸ ì‹œì‘")
        print("ğŸ“Š ì—…ë°ì´íŠ¸ ëª¨ë“œ: XBRL Excel + HTML ìŠ¤í¬ë˜í•‘")
        
        # ë‹¨ìœ„ ì •ë³´ ì¶œë ¥
        number_unit = os.environ.get('NUMBER_UNIT', 'million')
        unit_text = {
            'million': 'ë°±ë§Œì›',
            'hundred_million': 'ì–µì›',
            'billion': 'ì‹­ì–µì›'
        }.get(number_unit, 'ë°±ë§Œì›')
        print(f"ğŸ’° ìˆ«ì í‘œì‹œ ë‹¨ìœ„: {unit_text}")
        
        # 1. ë³´ê³ ì„œ ëª©ë¡ ì¡°íšŒ
        reports = self._get_recent_reports()
        if reports.empty:
            print("ğŸ“­ ìµœê·¼ ë³´ê³ ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"ğŸ“‹ ë°œê²¬ëœ ë³´ê³ ì„œ: {len(reports)}ê°œ")
        self.results['total_reports'] = len(reports)
        
        # 2. ê° ë³´ê³ ì„œì— ëŒ€í•´ XBRLê³¼ HTML ì²˜ë¦¬ ë³‘í–‰
        print("\n" + "="*50)
        print("ğŸ“„ XBRL Excel ë‹¤ìš´ë¡œë“œ ì‹œì‘")
        print("="*50)
        
        # XBRL ì²˜ë¦¬ (Playwright ì‚¬ìš©)
        with sync_playwright() as p:
            browser = p.chromium.launch(
                headless=True,
                args=[
                    '--disable-blink-features=AutomationControlled',
                    '--no-sandbox',
                    '--disable-setuid-sandbox',
                    '--disable-dev-shm-usage'
                ]
            )
            context = browser.new_context(
                accept_downloads=True,
                locale='ko-KR',
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            )
            
            try:
                with tqdm(total=len(reports), desc="XBRL ì²˜ë¦¬", unit="ê±´") as pbar:
                    for _, report in reports.iterrows():
                        self._process_xbrl_report(context, report)
                        pbar.update(1)
            finally:
                browser.close()
        
        # 3. HTML ìŠ¤í¬ë˜í•‘ ì²˜ë¦¬
        print("\n" + "="*50)
        print("ğŸŒ HTML ìŠ¤í¬ë˜í•‘ ì‹œì‘")
        print("="*50)
        
        with tqdm(total=len(reports), desc="HTML ì²˜ë¦¬", unit="ê±´") as pbar:
            for _, report in reports.iterrows():
                self._process_html_report(report['rcept_no'])
                pbar.update(1)
        
        # 4. XBRL Archive ì—…ë°ì´íŠ¸
        if os.environ.get('ENABLE_ARCHIVE_UPDATE', 'true').lower() == 'true':
            self._update_xbrl_archive()
        
        # 5. HTML Archive ì—…ë°ì´íŠ¸
        if os.environ.get('ENABLE_HTML_ARCHIVE', 'true').lower() == 'true':
            self._update_html_archive()
        
        # 6. ê²°ê³¼ ìš”ì•½
        self._print_summary()
        
        # 7. ë‹¤ìš´ë¡œë“œ í´ë” ì •ë¦¬
        self._cleanup_downloads()

    def _get_recent_reports(self):
        """ìµœê·¼ ë³´ê³ ì„œ ëª©ë¡ ì¡°íšŒ"""
        start_date, end_date = self._get_date_range()
        return self.dart.list(self.corp_code, start_date, end_date, kind='A', final='T')

    def _get_date_range(self):
        """ë‚ ì§œ ë²”ìœ„ ê³„ì‚°"""
        manual_start = os.environ.get('MANUAL_START_DATE')
        manual_end = os.environ.get('MANUAL_END_DATE')
        
        if manual_start and manual_end:
            print(f"ğŸ“… ìˆ˜ë™ ì„¤ì • ë‚ ì§œ: {manual_start} ~ {manual_end}")
            return manual_start, manual_end
        
        end_date = datetime.now()
        start_date = end_date - timedelta(days=90)
        date_range = start_date.strftime('%Y%m%d'), end_date.strftime('%Y%m%d')
        print(f"ğŸ“… ê¸°ë³¸ ë‚ ì§œ ë²”ìœ„ (ìµœê·¼ 3ê°œì›”): {date_range[0]} ~ {date_range[1]}")
        return date_range

    # === XBRL ê´€ë ¨ ë©”ì„œë“œ ===
    def _process_xbrl_report(self, context, report):
        """XBRL ë³´ê³ ì„œ ì²˜ë¦¬"""
        print(f"\nğŸ“„ XBRL ì²˜ë¦¬: {report['report_nm']} (ì ‘ìˆ˜ë²ˆí˜¸: {report['rcept_no']})")
        
        self.current_report = report
        page = context.new_page()
        
        try:
            viewer_url = f"https://opendart.fss.or.kr/xbrl/viewer/main.do?rcpNo={report['rcept_no']}"
            print(f"ğŸŒ í˜ì´ì§€ ì—´ê¸°: {viewer_url}")
            
            page.goto(viewer_url, wait_until='networkidle', timeout=60000)
            page.wait_for_timeout(2000)
            
            download_button = page.locator('button.btnDown').first
            if not download_button.is_visible():
                print("âš ï¸ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                self.results['xbrl']['failed_downloads'].append(report['rcept_no'])
                return
            
            print("ğŸ–±ï¸ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í´ë¦­")
            
            with page.expect_popup() as popup_info:
                download_button.click()
            
            popup = popup_info.value
            popup.wait_for_load_state('networkidle')
            
            self._download_excel_files(popup, report['rcept_no'])
            popup.close()
            
        except Exception as e:
            print(f"âŒ XBRL ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            self.results['xbrl']['failed_downloads'].append(report['rcept_no'])
        finally:
            page.close()

    def _download_excel_files(self, popup_page, rcept_no):
        """íŒì—… í˜ì´ì§€ì—ì„œ Excel íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
        try:
            popup_page.wait_for_timeout(2000)
            print(f"ğŸ“ íŒì—… í˜ì´ì§€ URL: {popup_page.url}")
            
            download_links = popup_page.locator('a.btnFile')
            link_count = download_links.count()
            print(f"ğŸ“„ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ íŒŒì¼ ìˆ˜: {link_count}ê°œ")
            
            # ì¬ë¬´ì œí‘œ ë‹¤ìš´ë¡œë“œ
            if link_count >= 1:
                print("ğŸ“¥ ì¬ë¬´ì œí‘œ ë‹¤ìš´ë¡œë“œ ì¤‘...")
                
                with popup_page.expect_download() as download_info:
                    download_links.nth(0).click()
                
                download = download_info.value
                file_path = os.path.join(self.download_dir, f"ì¬ë¬´ì œí‘œ_{rcept_no}.xlsx")
                download.save_as(file_path)
                
                print(f"âœ… ì¬ë¬´ì œí‘œ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {file_path}")
                self.results['xbrl']['downloaded_files'].append(file_path)
                self.results['xbrl']['excel_files']['financial'] = file_path
                
                self._upload_excel_to_sheets(file_path, "ì¬ë¬´ì œí‘œ", rcept_no)
                popup_page.wait_for_timeout(2000)
            
            # ì¬ë¬´ì œí‘œì£¼ì„ ë‹¤ìš´ë¡œë“œ
            if link_count >= 2:
                print("ğŸ“¥ ì¬ë¬´ì œí‘œì£¼ì„ ë‹¤ìš´ë¡œë“œ ì¤‘...")
                
                with popup_page.expect_download() as download_info:
                    download_links.nth(1).click()
                
                download = download_info.value
                file_path = os.path.join(self.download_dir, f"ì¬ë¬´ì œí‘œì£¼ì„_{rcept_no}.xlsx")
                download.save_as(file_path)
                
                print(f"âœ… ì¬ë¬´ì œí‘œì£¼ì„ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {file_path}")
                self.results['xbrl']['downloaded_files'].append(file_path)
                self.results['xbrl']['excel_files']['notes'] = file_path
                
                self._upload_excel_to_sheets(file_path, "ì¬ë¬´ì œí‘œì£¼ì„", rcept_no)
                
        except Exception as e:
            print(f"âŒ Excel ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            self.results['xbrl']['failed_downloads'].append(f"Excel_{rcept_no}")

    # === HTML ìŠ¤í¬ë˜í•‘ ê´€ë ¨ ë©”ì„œë“œ ===
    def _process_html_report(self, rcept_no):
        """HTML ë³´ê³ ì„œ ì²˜ë¦¬"""
        try:
            print(f"\nğŸŒ HTML ì²˜ë¦¬: ë³´ê³ ì„œ ì ‘ìˆ˜ë²ˆí˜¸ {rcept_no}")
            
            # ë³´ê³ ì„œ í•˜ìœ„ ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ
            report_index = self.dart.sub_docs(rcept_no)
            
            # HTML ëŒ€ìƒ ì‹œíŠ¸ë§Œ í•„í„°ë§ (ì¬ë¬´ì œí‘œ ê´€ë ¨ ì œì™¸)
            target_docs = report_index[report_index['title'].isin(self.HTML_TARGET_SHEETS)]
            
            print(f"ğŸ“ ì²˜ë¦¬í•  HTML ë¬¸ì„œ: {len(target_docs)}ê°œ")
            
            for _, doc in target_docs.iterrows():
                self._update_html_worksheet(doc['title'], doc['url'])
                
        except Exception as e:
            print(f"âŒ HTML ë³´ê³ ì„œ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

    def _update_html_worksheet(self, sheet_name, url):
        """HTML ì›Œí¬ì‹œíŠ¸ ì—…ë°ì´íŠ¸"""
        try:
            # ì›Œí¬ì‹œíŠ¸ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
            try:
                worksheet = self.workbook.worksheet(sheet_name)
            except gspread.exceptions.WorksheetNotFound:
                worksheet = self.workbook.add_worksheet(sheet_name, 1000, 10)
                print(f"ğŸ†• ìƒˆ ì‹œíŠ¸ ìƒì„±: {sheet_name}")
            
            # HTML ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
            response = requests.get(url)
            if response.status_code == 200:
                self._process_html_content(worksheet, response.text)
                print(f"âœ… HTML ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {sheet_name}")
                self.results['html']['processed_sheets'].append(sheet_name)
            else:
                print(f"âŒ HTML ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {sheet_name}")
                self.results['html']['failed_sheets'].append(sheet_name)
                
        except Exception as e:
            print(f"âŒ HTML ì›Œí¬ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ ({sheet_name}): {str(e)}")
            self.results['html']['failed_sheets'].append(sheet_name)

    def _process_html_content(self, worksheet, html_content):
        """HTML ë‚´ìš© ì²˜ë¦¬ ë° ì›Œí¬ì‹œíŠ¸ ì—…ë°ì´íŠ¸"""
        soup = BeautifulSoup(html_content, 'html.parser')
        tables = soup.find_all("table")
        
        worksheet.clear()
        all_data = []
        
        for table in tables:
            table_data = parser.make2d(table)
            if table_data:
                all_data.extend(table_data)
        
        # ë°°ì¹˜ ì—…ë°ì´íŠ¸
        BATCH_SIZE = 100
        for i in range(0, len(all_data), BATCH_SIZE):
            batch = all_data[i:i + BATCH_SIZE]
            try:
                worksheet.append_rows(batch)
                time.sleep(1)  # API ì œí•œ íšŒí”¼
            except gspread.exceptions.APIError as e:
                if 'Quota exceeded' in str(e):
                    print("â³ í• ë‹¹ëŸ‰ ì œí•œ. 60ì´ˆ ëŒ€ê¸°...")
                    time.sleep(60)
                    worksheet.append_rows(batch)
                else:
                    raise e

    def _update_html_archive(self):
        """HTML Archive ì‹œíŠ¸ ì—…ë°ì´íŠ¸"""
        try:
            print("\nğŸ“Š HTML Archive ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì‹œì‘...")
            
            # Dart_Archive ì‹œíŠ¸ ì ‘ê·¼
            archive = self.workbook.worksheet('Dart_Archive')
            sheet_values = archive.get_all_values()
            
            if not sheet_values:
                print("âš ï¸ Dart_Archive ì‹œíŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                return
            
            last_col = len(sheet_values[0])
            control_value = archive.cell(1, last_col).value
            
            # control_valueì— ë”°ë¼ ì—´ ì¡°ì •
            if control_value:
                last_col += 1
            
            # ì•„ì¹´ì´ë¸Œ ë°ì´í„° ì²˜ë¦¬
            self._process_archive_data(archive, 10, last_col)
            print("âœ… HTML Archive ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ HTML Archive ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")

    def _process_archive_data(self, archive, start_row, last_col):
        """ì•„ì¹´ì´ë¸Œ ë°ì´í„° ì²˜ë¦¬ (HTML ìŠ¤í¬ë˜í•‘ìš©)"""
        try:
            current_cols = archive.col_count
            current_col_letter = self._get_column_letter(current_cols)
            target_col_letter = self._get_column_letter(last_col)
            
            print(f"ì‹œì‘ í–‰: {start_row}, ëŒ€ìƒ ì—´: {last_col} ({target_col_letter})")
            print(f"í˜„ì¬ ì‹œíŠ¸ ì—´ ìˆ˜: {current_cols} ({current_col_letter})")
            
            # í•„ìš”í•œ ê²½ìš° ì‹œíŠ¸ í¬ê¸° ì¡°ì •
            if last_col >= current_cols:
                new_cols = last_col + 5
                try:
                    print(f"ì‹œíŠ¸ í¬ê¸°ë¥¼ {current_cols}({current_col_letter})ì—ì„œ {new_cols}({self._get_column_letter(new_cols)})ë¡œ ì¡°ì •í•©ë‹ˆë‹¤.")
                    archive.resize(rows=archive.row_count, cols=new_cols)
                    time.sleep(2)
                    print("ì‹œíŠ¸ í¬ê¸° ì¡°ì • ì™„ë£Œ")
                except Exception as e:
                    print(f"ì‹œíŠ¸ í¬ê¸° ì¡°ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    raise

            # ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘
            all_rows = archive.get_all_values()
            update_data = []
            sheet_cache = {}
            
            sheet_rows = {}
            for row_idx in range(start_row - 1, len(all_rows)):
                if len(all_rows[row_idx]) < 5:
                    print(f"í–‰ {row_idx + 1}: ë°ì´í„° ë¶€ì¡± (ì»¬ëŸ¼ ìˆ˜: {len(all_rows[row_idx])})")
                    continue
                    
                sheet_name = all_rows[row_idx][0]
                if not sheet_name:
                    print(f"í–‰ {row_idx + 1}: ì‹œíŠ¸ëª… ì—†ìŒ")
                    continue
                
                print(f"í–‰ {row_idx + 1} ì²˜ë¦¬: ì‹œíŠ¸={sheet_name}, " + 
                      f"í‚¤ì›Œë“œ={all_rows[row_idx][1]}, n={all_rows[row_idx][2]}, " +
                      f"x={all_rows[row_idx][3]}, y={all_rows[row_idx][4]}")
                
                if sheet_name not in sheet_rows:
                    sheet_rows[sheet_name] = []
                sheet_rows[sheet_name].append({
                    'row_idx': row_idx + 1,
                    'keyword': all_rows[row_idx][1],
                    'n': all_rows[row_idx][2],
                    'x': all_rows[row_idx][3],
                    'y': all_rows[row_idx][4]
                })
            
            for sheet_name, rows in sheet_rows.items():
                try:
                    print(f"\nì‹œíŠ¸ '{sheet_name}' ì²˜ë¦¬ ì¤‘...")
                    print(f"ê²€ìƒ‰í•  í‚¤ì›Œë“œ ìˆ˜: {len(rows)}")
                    
                    if sheet_name not in sheet_cache:
                        search_sheet = self.workbook.worksheet(sheet_name)
                        sheet_data = search_sheet.get_all_values()
                        df = pd.DataFrame(sheet_data)
                        sheet_cache[sheet_name] = df
                        print(f"ì‹œíŠ¸ '{sheet_name}' ë°ì´í„° ë¡œë“œ ì™„ë£Œ (í¬ê¸°: {df.shape})")
                    
                    df = sheet_cache[sheet_name]
                    
                    for row in rows:
                        keyword = row['keyword']
                        if not keyword or not row['n'] or not row['x'] or not row['y']:
                            print(f"í–‰ {row['row_idx']}: ê²€ìƒ‰ ì •ë³´ ë¶€ì¡±")
                            continue
                        
                        try:
                            n = int(row['n'])
                            x = int(row['x'])
                            y = int(row['y'])
                            
                            keyword_positions = []
                            for idx, df_row in df.iterrows():
                                for col_idx, value in enumerate(df_row):
                                    if value == keyword:
                                        keyword_positions.append((idx, col_idx))
                            
                            print(f"í‚¤ì›Œë“œ '{keyword}' ê²€ìƒ‰ ê²°ê³¼: {len(keyword_positions)}ê°œ ë°œê²¬")
                            
                            if keyword_positions and len(keyword_positions) >= n:
                                target_pos = keyword_positions[n - 1]
                                target_row = target_pos[0] + y
                                target_col = target_pos[1] + x
                                
                                if target_row >= 0 and target_row < df.shape[0] and \
                                   target_col >= 0 and target_col < df.shape[1]:
                                    value = df.iat[target_row, target_col]
                                    cleaned_value = self._remove_parentheses(str(value))
                                    print(f"ì°¾ì€ ê°’: {cleaned_value} (í‚¤ì›Œë“œ: {keyword})")
                                    update_data.append((row['row_idx'], cleaned_value))
                                else:
                                    print(f"í–‰ {row['row_idx']}: ëŒ€ìƒ ìœ„ì¹˜ê°€ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¨ ({target_row}, {target_col})")
                            else:
                                print(f"í–‰ {row['row_idx']}: í‚¤ì›Œë“œ '{keyword}'ë¥¼ {n}ë²ˆì§¸ë¡œ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                        
                        except Exception as e:
                            print(f"í–‰ {row['row_idx']} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                
                except Exception as e:
                    print(f"ì‹œíŠ¸ '{sheet_name}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            
            print(f"\nì—…ë°ì´íŠ¸í•  ë°ì´í„° ìˆ˜: {len(update_data)}")
            
            if update_data:
                try:
                    # ì—…ë°ì´íŠ¸í•  ì—´ì˜ ë°ì´í„°ë§Œ ì¤€ë¹„
                    column_data = []
                    min_row = min(row for row, _ in update_data)
                    max_row = max(row for row, _ in update_data)
                    
                    # ë¹ˆ ë°ì´í„°ë¡œ ì´ˆê¸°í™”
                    for _ in range(max_row - min_row + 1):
                        column_data.append([''])
                    
                    # ì—…ë°ì´íŠ¸í•  ë°ì´í„° ì‚½ì…
                    for row, value in update_data:
                        adjusted_row = row - min_row
                        column_data[adjusted_row] = [value]
                    
                    # ë‹¨ì¼ ì—´ ì—…ë°ì´íŠ¸
                    range_label = f'{target_col_letter}{min_row}:{target_col_letter}{max_row}'
                    print(f"ì—…ë°ì´íŠ¸ ë²”ìœ„: {range_label}")
                    
                    archive.batch_update([{
                        'range': range_label,
                        'values': column_data
                    }])
                    print(f"ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ: {min_row}~{max_row} í–‰")
                    
                    # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
                    today = datetime.now()
                    three_months_ago = today - timedelta(days=90)
                    year = str(three_months_ago.year)[2:]
                    quarter = (three_months_ago.month - 1) // 3 + 1
                    quarter_text = f"{quarter}Q{year}"
                    
                    meta_updates = [
                        {'range': 'J1', 'values': [[today.strftime('%Y-%m-%d')]]},
                        {'range': f'{target_col_letter}1', 'values': [['1']]},
                        {'range': f'{target_col_letter}5', 'values': [[today.strftime('%Y-%m-%d')]]},
                        {'range': f'{target_col_letter}6', 'values': [[quarter_text]]}
                    ]
                    
                    archive.batch_update(meta_updates)
                    print(f"ìµœì¢… ì—…ë°ì´íŠ¸ ì™„ë£Œ (ì´ì „ ë¶„ê¸°: {quarter_text})")
                    
                    message = (
                        f"ğŸ”„ HTML Archive ì—…ë°ì´íŠ¸ ì™„ë£Œ\n\n"
                        f"â€¢ ì¢…ëª©: {self.company_name} ({self.corp_code})\n"
                        f"â€¢ ë¶„ê¸°: {quarter_text}\n"
                        f"â€¢ ì—…ë°ì´íŠ¸ ì¼ì‹œ: {today.strftime('%Y-%m-%d %H:%M:%S')}\n"
                        f"â€¢ ì²˜ë¦¬ëœ í–‰: {len(update_data)}ê°œ\n"
                        f"â€¢ ì‹œíŠ¸ ì—´: {target_col_letter} (#{last_col})"
                    )
                    self._send_telegram_message(message)
                    
                except Exception as e:
                    error_msg = f"ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                    print(error_msg)
                    self._send_telegram_message(f"âŒ {error_msg}")
                    raise e
                    
        except Exception as e:
            error_msg = f"ì•„ì¹´ì´ë¸Œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            print(error_msg)
            self._send_telegram_message(f"âŒ {error_msg}")
            raise e

    def _remove_parentheses(self, value):
        """ê´„í˜¸ ë‚´ìš© ì œê±°"""
        if not value:
            return value
        return re.sub(r'\s*\(.*?\)\s*', '', value).replace('%', '')

    def _upload_excel_to_sheets(self, file_path, file_type, rcept_no):
        """Excel íŒŒì¼ì„ Google Sheetsì— ì—…ë¡œë“œ"""
        try:
            wb = load_workbook(file_path, data_only=True)
            print(f"ğŸ“Š Excel íŒŒì¼ ì—´ê¸° ì™„ë£Œ. ì‹œíŠ¸ ëª©ë¡: {wb.sheetnames}")
            
            all_sheets_data = {}
            
            print(f"ğŸ“¥ {file_type} ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            with tqdm(total=len(wb.sheetnames), desc="ë°ì´í„° ìˆ˜ì§‘", unit="ì‹œíŠ¸", leave=False) as pbar:
                for sheet_name in wb.sheetnames:
                    data = []
                    worksheet = wb[sheet_name]
                    for row in worksheet.iter_rows(values_only=True):
                        row_data = [str(cell) if cell is not None else '' for cell in row]
                        if any(row_data):
                            data.append(row_data)
                    
                    if data:
                        gsheet_name = f"{file_type}_{sheet_name.replace(' ', '_')}"
                        if len(gsheet_name) > 100:
                            gsheet_name = gsheet_name[:97] + "..."
                        
                        all_sheets_data[gsheet_name] = {
                            'original_name': sheet_name,
                            'data': data
                        }
                    
                    pbar.update(1)
            
            print(f"ğŸ“¤ Google Sheetsì— ì—…ë¡œë“œ ì¤‘... (ì´ {len(all_sheets_data)}ê°œ ì‹œíŠ¸)")
            self._batch_upload_to_google_sheets(all_sheets_data, rcept_no)
            
        except Exception as e:
            print(f"âŒ Excel ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            self.results['xbrl']['failed_uploads'].append(file_path)

    def _batch_upload_to_google_sheets(self, all_sheets_data, rcept_no):
        """ì—¬ëŸ¬ ì‹œíŠ¸ë¥¼ ë°°ì¹˜ë¡œ Google Sheetsì— ì—…ë¡œë“œ"""
        try:
            existing_sheets = [ws.title for ws in self.workbook.worksheets()]
            
            sheets_to_create = []
            sheets_to_update = []
            
            for gsheet_name in all_sheets_data:
                if gsheet_name in existing_sheets:
                    sheets_to_update.append(gsheet_name)
                else:
                    sheets_to_create.append(gsheet_name)
            
            # ìƒˆ ì‹œíŠ¸ ìƒì„±
            if sheets_to_create:
                print(f"ğŸ†• ìƒˆ ì‹œíŠ¸ {len(sheets_to_create)}ê°œ ìƒì„± ì¤‘...")
                
                batch_size = 5
                for i in range(0, len(sheets_to_create), batch_size):
                    batch = sheets_to_create[i:i + batch_size]
                    
                    for sheet_name in batch:
                        try:
                            data = all_sheets_data[sheet_name]['data']
                            rows = max(1000, len(data) + 100)
                            cols = max(26, len(data[0]) + 5) if data else 26
                            self.workbook.add_worksheet(sheet_name, rows, cols)
                        except Exception as e:
                            print(f"âš ï¸ ì‹œíŠ¸ ìƒì„± ì‹¤íŒ¨ {sheet_name}: {str(e)}")
                    
                    time.sleep(3)
            
            # ê¸°ì¡´ ì‹œíŠ¸ í´ë¦¬ì–´
            if sheets_to_update:
                print(f"ğŸ§¹ ê¸°ì¡´ ì‹œíŠ¸ {len(sheets_to_update)}ê°œ ì´ˆê¸°í™” ì¤‘...")
                for sheet_name in sheets_to_update:
                    try:
                        worksheet = self.workbook.worksheet(sheet_name)
                        worksheet.clear()
                        time.sleep(1)
                    except Exception as e:
                        print(f"âš ï¸ ì‹œíŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨ {sheet_name}: {str(e)}")
            
            # ë°ì´í„° ì—…ë¡œë“œ
            print(f"ğŸ“ ë°ì´í„° ì—…ë¡œë“œ ì¤‘...")
            
            upload_count = 0
            total_sheets = len(all_sheets_data)
            
            with tqdm(total=total_sheets, desc="ì‹œíŠ¸ ì—…ë¡œë“œ", unit="ì‹œíŠ¸") as pbar:
                for gsheet_name, sheet_info in all_sheets_data.items():
                    try:
                        worksheet = self.workbook.worksheet(gsheet_name)
                        
                        header = [
                            [f"ì—…ë°ì´íŠ¸: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"],
                            [f"ë³´ê³ ì„œ: {rcept_no}"],
                            [f"ì›ë³¸ ì‹œíŠ¸: {sheet_info['original_name']}"],
                            []
                        ]
                        
                        all_data = header + sheet_info['data']
                        
                        if len(all_data) > 0:
                            end_row = len(all_data)
                            end_col = max(len(row) for row in all_data) if all_data else 1
                            end_col_letter = self._get_column_letter(end_col - 1)
                            
                            range_name = f'A1:{end_col_letter}{end_row}'
                            worksheet.update(values=all_data, range_name=range_name)
                        
                        self.results['xbrl']['uploaded_sheets'].append(gsheet_name)
                        upload_count += 1
                        
                        if upload_count % 10 == 0:
                            print(f"  ğŸ’¤ API ì œí•œ íšŒí”¼ë¥¼ ìœ„í•´ 10ì´ˆ ëŒ€ê¸° ì¤‘...")
                            time.sleep(10)
                        else:
                            time.sleep(2)
                        
                    except Exception as e:
                        print(f"âŒ ì‹œíŠ¸ ì—…ë¡œë“œ ì‹¤íŒ¨ '{gsheet_name}': {str(e)}")
                        self.results['xbrl']['failed_uploads'].append(gsheet_name)
                        
                        if "429" in str(e):
                            print(f"  â³ API í• ë‹¹ëŸ‰ ì´ˆê³¼. 30ì´ˆ ëŒ€ê¸° ì¤‘...")
                            time.sleep(30)
                    
                    pbar.update(1)
            
            print(f"âœ… ì—…ë¡œë“œ ì™„ë£Œ: ì„±ê³µ {upload_count}/{total_sheets}ê°œ")
            
        except Exception as e:
            print(f"âŒ ë°°ì¹˜ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

    def _update_xbrl_archive(self):
        """XBRL Archive ì‹œíŠ¸ ì—…ë°ì´íŠ¸"""
        print("\nğŸ“Š XBRL Archive ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì‹œì‘...")
        
        try:
            if 'financial' in self.results['xbrl']['excel_files']:
                print("ğŸ“ˆ XBRL ì¬ë¬´ì œí‘œ Archive ì—…ë°ì´íŠ¸ ì¤‘...")
                self._update_single_xbrl_archive('Dart_Archive_XBRL_ì¬ë¬´ì œí‘œ', 
                                               self.results['xbrl']['excel_files']['financial'], 
                                               'financial')
            
            if 'notes' in self.results['xbrl']['excel_files']:
                print("ğŸ“ XBRL ì¬ë¬´ì œí‘œì£¼ì„ Archive ì—…ë°ì´íŠ¸ ì¤‘...")
                
                # ì£¼ì„ ë°ì´í„° ìˆ˜ì •ëœ ë©”ì„œë“œ ì ìš©
                self._update_single_xbrl_archive('Dart_Archive_XBRL_ì£¼ì„_ì—°ê²°', 
                                               self.results['xbrl']['excel_files']['notes'], 
                                               'notes_consolidated')
                
                self._update_single_xbrl_archive('Dart_Archive_XBRL_ì£¼ì„_ë³„ë„', 
                                               self.results['xbrl']['excel_files']['notes'], 
                                               'notes_standalone')
            
            print("âœ… XBRL Archive ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ XBRL Archive ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")

    def _update_single_xbrl_archive(self, sheet_name, file_path, file_type):
        """ê°œë³„ XBRL Archive ì‹œíŠ¸ ì—…ë°ì´íŠ¸"""
        try:
            # Archive ì‹œíŠ¸ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
            archive_exists = False
            try:
                archive_sheet = self.workbook.worksheet(sheet_name)
                archive_exists = True
                print(f"ğŸ“„ ê¸°ì¡´ {sheet_name} ì‹œíŠ¸ ë°œê²¬")
            except gspread.exceptions.WorksheetNotFound:
                print(f"ğŸ†• ìƒˆë¡œìš´ {sheet_name} ì‹œíŠ¸ ìƒì„±")
                time.sleep(2)
                max_rows = 2000 if 'notes' in file_type else 1000
                archive_sheet = self.workbook.add_worksheet(sheet_name, max_rows, 20)
                time.sleep(2)
            
            # ì‹œíŠ¸ê°€ ìƒˆë¡œ ìƒì„±ëœ ê²½ìš° í—¤ë” ì„¤ì •
            if not archive_exists:
                header_type = file_type
                if file_type.startswith('notes_'):
                    header_type = 'notes'
                self._setup_xbrl_archive_header(archive_sheet, header_type)
                time.sleep(3)
            
            # í˜„ì¬ ë§ˆì§€ë§‰ ë°ì´í„° ì—´ ì°¾ê¸° (Mì—´ë¶€í„°)
            last_col = self._find_last_data_column(archive_sheet)
            
            # Excel íŒŒì¼ ì½ê¸°
            wb = load_workbook(file_path, data_only=True)
            
            # ë°ì´í„° ì¶”ì¶œ ë° ì—…ë°ì´íŠ¸
            if file_type == 'financial':
                self._update_xbrl_financial_archive_batch(archive_sheet, wb, last_col)
            elif file_type == 'notes_consolidated':
                self._update_xbrl_notes_archive_batch(archive_sheet, wb, last_col, 'consolidated')
            elif file_type == 'notes_standalone':
                self._update_xbrl_notes_archive_batch(archive_sheet, wb, last_col, 'standalone')
                
        except Exception as e:
            print(f"âŒ {sheet_name} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
            
            if "429" in str(e):
                print(f"  â³ API í• ë‹¹ëŸ‰ ì´ˆê³¼. 60ì´ˆ ëŒ€ê¸° ì¤‘...")
                time.sleep(60)

    def _setup_xbrl_archive_header(self, sheet, file_type):
        """XBRL Archive ì‹œíŠ¸ í—¤ë” ì„¤ì •"""
        try:
            current_date = datetime.now().strftime('%Y-%m-%d')
            
            number_unit = os.environ.get('NUMBER_UNIT', 'million')
            unit_text = {
                'million': 'ë°±ë§Œì›',
                'hundred_million': 'ì–µì›',
                'billion': 'ì‹­ì–µì›'
            }.get(number_unit, 'ë°±ë§Œì›')
            
            header_data = []
            
            if file_type == 'financial':
                title_row = ['DART Archive XBRL ì¬ë¬´ì œí‘œ', '', '', '', '', '', '', '', '', f'ìµœì¢…ì—…ë°ì´íŠ¸: {current_date}', '', 'ê³„ì •ê³¼ëª©']
            else:
                title_row = ['DART Archive XBRL ì¬ë¬´ì œí‘œì£¼ì„', '', '', '', '', '', '', '', '', f'ìµœì¢…ì—…ë°ì´íŠ¸: {current_date}', '', 'ê³„ì •ê³¼ëª©']
            header_data.append(title_row)
            
            company_row = [f'íšŒì‚¬ëª…: {self.company_name}', '', '', '', '', '', '', '', '', f'ë‹¨ìœ„: {unit_text}', '', 'í•­ëª©ëª…â†“']
            header_data.append(company_row)
            
            stock_row = [f'ì¢…ëª©ì½”ë“œ: {self.corp_code}', '', '', '', '', '', '', '', '', '', '', '']
            header_data.append(stock_row)
            
            for _ in range(3):
                header_data.append(['', '', '', '', '', '', '', '', '', '', '', ''])
            
            end_row = len(header_data)
            range_name = f'A1:L{end_row}'
            
            print(f"  ğŸ“‹ XBRL Archive ê¸°ë³¸ í—¤ë” ì„¤ì •: {range_name}")
            sheet.update(values=header_data, range_name=range_name)
            
            print(f"  âœ… XBRL Archive ê¸°ë³¸ ë ˆì´ì•„ì›ƒ ì™„ë£Œ")
            
        except Exception as e:
            print(f"  âŒ XBRL Archive í—¤ë” ì„¤ì • ì‹¤íŒ¨: {str(e)}")

    def _find_last_data_column(self, sheet):
        """ë§ˆì§€ë§‰ ë°ì´í„° ì—´ ì°¾ê¸° (Mì—´ë¶€í„° ì‹œì‘)"""
        try:
            row_2_values = sheet.row_values(2)
            
            last_col = 11  # Mì—´ = 12ë²ˆì§¸ ì—´ (0-based indexì—ì„œëŠ” 11)
            
            for i in range(11, len(row_2_values)):
                if row_2_values[i]:
                    last_col = i
            
            next_col = last_col + 1
            
            if next_col < 11:
                next_col = 11
            
            col_letter = self._get_column_letter(next_col)
            print(f"ğŸ“ ìƒˆ ë°ì´í„° ì¶”ê°€ ìœ„ì¹˜: {col_letter}ì—´ (ì¸ë±ìŠ¤: {next_col})")
            
            return next_col
            
        except Exception as e:
            print(f"âš ï¸ ë§ˆì§€ë§‰ ì—´ ì°¾ê¸° ì‹¤íŒ¨: {str(e)}")
            return 11

    def _update_xbrl_financial_archive_batch(self, sheet, wb, col_index):
        """XBRL ì¬ë¬´ì œí‘œ Archive ì—…ë°ì´íŠ¸"""
        try:
            print(f"  ğŸ“Š XBRL ì¬ë¬´ì œí‘œ ë°ì´í„° ì¶”ì¶œ ì¤‘...")
            
            col_letter = self._get_column_letter(col_index)
            print(f"  ğŸ“ ë°ì´í„° ì…ë ¥ ìœ„ì¹˜: {col_letter}ì—´")
            
            # ê¸°ì¡´ Lì—´ì˜ ê³„ì •ëª… ì½ì–´ì˜¤ê¸°
            existing_accounts = set()
            try:
                l_column_values = sheet.col_values(12)
                for idx, account in enumerate(l_column_values[6:], start=7):
                    if account and account.strip():
                        existing_accounts.add(account.strip())
                
                print(f"  ğŸ“‹ ê¸°ì¡´ ê³„ì •ëª… {len(existing_accounts)}ê°œ ë°œê²¬")
            except Exception as e:
                print(f"  âš ï¸ ê¸°ì¡´ ê³„ì •ëª… ì½ê¸° ì‹¤íŒ¨: {str(e)}")
            
            # í—¤ë” ì •ë³´ ì—…ë°ì´íŠ¸
            report_date = datetime.now().strftime('%Y-%m-%d')
            quarter_info = self._get_quarter_info()
            
            # ëª¨ë“  ì¬ë¬´ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì—ì„œ ì¤€ë¹„
            all_account_data, all_value_data = self._prepare_financial_data_for_batch_update(wb)
            
            # ì‹ ê·œ ê³„ì •ëª… ì¶”ì 
            new_accounts = []
            for idx, account_row in enumerate(all_account_data):
                if account_row and account_row[0]:
                    account_name = account_row[0]
                    if (not account_name.startswith('[') and 
                        not account_name.startswith('===') and
                        account_name not in existing_accounts):
                        new_accounts.append((idx, account_name))
            
            if new_accounts:
                print(f"  ğŸ†• ì‹ ê·œ ê³„ì •ëª… {len(new_accounts)}ê°œ ë°œê²¬")
            
            # ë°°ì¹˜ ì—…ë°ì´íŠ¸
            print(f"  ğŸš€ ëŒ€ìš©ëŸ‰ ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì‹œì‘...")
            
            # í—¤ë” ì •ë³´
            header_range = f'{col_letter}1:{col_letter}2'
            header_data = [[quarter_info], [report_date]]
            sheet.update(values=header_data, range_name=header_range)
            print(f"    âœ… í—¤ë” ì •ë³´ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            
            # Lì—´ ê³„ì •ëª…
            if all_account_data:
                account_range = f'L7:L{6 + len(all_account_data)}'
                sheet.update(values=all_account_data, range_name=account_range)
                print(f"    âœ… Lì—´ ê³„ì •ëª… ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            
            time.sleep(2)
            
            # Mì—´ ê°’
            if all_value_data:
                value_range = f'{col_letter}7:{col_letter}{6 + len(all_value_data)}'
                sheet.update(values=all_value_data, range_name=value_range)
                print(f"    âœ… {col_letter}ì—´ ê°’ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            
            print(f"  âœ… XBRL ì¬ë¬´ì œí‘œ Archive ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ XBRL ì¬ë¬´ì œí‘œ Archive ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")

    def _prepare_financial_data_for_batch_update(self, wb):
        """ì¬ë¬´ ë°ì´í„°ë¥¼ ë°°ì¹˜ ì—…ë°ì´íŠ¸ìš©ìœ¼ë¡œ ì¤€ë¹„"""
        try:
            print(f"  ğŸ”„ ë°°ì¹˜ ì—…ë°ì´íŠ¸ìš© ë°ì´í„° ì¤€ë¹„ ì¤‘...")
            
            all_account_data = []
            all_value_data = []
            
            # Dë¡œ ì‹œì‘í•˜ëŠ” ì‹œíŠ¸ ì²˜ë¦¬
            d_sheets = [name for name in wb.sheetnames if name.startswith('D')]
            print(f"  ğŸ“‹ Dë¡œ ì‹œì‘í•˜ëŠ” ì‹œíŠ¸ {len(d_sheets)}ê°œ ë°œê²¬")
            
            for sheet_name in sorted(d_sheets):
                worksheet = wb[sheet_name]
                
                # ì‹œíŠ¸ ì œëª© ì°¾ê¸°
                sheet_title = self._find_sheet_title(worksheet) or sheet_name
                
                # ì—°ê²°/ë³„ë„ êµ¬ë¶„
                sheet_type = ""
                if 'ì—°ê²°' in sheet_title or sheet_name.endswith('0'):
                    sheet_type = "[ì—°ê²°]"
                elif 'ë³„ë„' in sheet_title or sheet_name.endswith('5'):
                    sheet_type = "[ë³„ë„]"
                else:
                    sheet_type = "[ê¸°íƒ€]"
                
                # ì¬ë¬´ì œí‘œ ì¢…ë¥˜ íŒë‹¨
                fs_type = ""
                if 'ì¬ë¬´ìƒíƒœí‘œ' in sheet_title:
                    fs_type = "ì¬ë¬´ìƒíƒœí‘œ"
                elif 'ì†ìµê³„ì‚°ì„œ' in sheet_title or 'í¬ê´„ì†ìµ' in sheet_title:
                    fs_type = "ì†ìµê³„ì‚°ì„œ"
                elif 'í˜„ê¸ˆíë¦„í‘œ' in sheet_title:
                    fs_type = "í˜„ê¸ˆíë¦„í‘œ"
                elif 'ìë³¸ë³€ë™í‘œ' in sheet_title:
                    fs_type = "ìë³¸ë³€ë™í‘œ"
                else:
                    continue
                
                # ì‹œíŠ¸ëª… í—¤ë” ì¶”ê°€
                header_text = f"{sheet_type} {fs_type} ({sheet_name})"
                all_account_data.append([header_text])
                all_value_data.append([''])
                
                # ë°ì´í„° ì¶”ì¶œ
                data_count = 0
                for row_idx in range(1, min(worksheet.max_row + 1, 500)):
                    row = list(worksheet.iter_rows(min_row=row_idx, max_row=row_idx, values_only=True))[0]
                    
                    if not row or len(row) < 2:
                        continue
                    
                    # Aì—´: ê³„ì •ëª…
                    account_name = str(row[0]).strip() if row[0] else ''
                    
                    if (not account_name or 
                        len(account_name) < 2 or 
                        account_name.startswith('[') or
                        account_name.startswith('(ë‹¨ìœ„')):
                        continue
                    
                    # Bì—´: ê°’
                    value = None
                    if row[1] is not None:
                        if isinstance(row[1], (int, float)):
                            value = row[1]
                        elif isinstance(row[1], str):
                            try:
                                clean_str = str(row[1]).replace(',', '').replace('(', '-').replace(')', '').strip()
                                if clean_str and clean_str != '-':
                                    value = float(clean_str)
                            except:
                                pass
                    
                    all_account_data.append([account_name])
                    all_value_data.append([self._format_number_for_archive(value) if value else ''])
                    data_count += 1
                
                if data_count > 0:
                    print(f"    âœ… {sheet_name}: {data_count}ê°œ í•­ëª© ì¶”ê°€")
                    all_account_data.append([''])
                    all_value_data.append([''])
            
            return all_account_data, all_value_data
            
        except Exception as e:
            print(f"  âŒ ë°°ì¹˜ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {str(e)}")
            return [], []

    def _find_sheet_title(self, worksheet):
        """ì‹œíŠ¸ ì œëª© ì°¾ê¸°"""
        try:
            for row in worksheet.iter_rows(min_row=1, max_row=10, values_only=True):
                for cell in row:
                    if cell and isinstance(cell, str):
                        if any(keyword in str(cell) for keyword in ['ì¬ë¬´ìƒíƒœí‘œ', 'ì†ìµê³„ì‚°ì„œ', 'í˜„ê¸ˆíë¦„í‘œ', 'ìë³¸ë³€ë™í‘œ', 'í¬ê´„ì†ìµ']):
                            return str(cell).strip()
            return None
        except:
            return None

    def _update_xbrl_notes_archive_batch(self, sheet, wb, col_index, notes_type='consolidated'):
        """XBRL ì¬ë¬´ì œí‘œì£¼ì„ Archive ì—…ë°ì´íŠ¸"""
        try:
            print(f"  ğŸ“ XBRL ì£¼ì„ ë°ì´í„° ë¶„ì„ ì¤‘... ({notes_type})")
            
            col_letter = self._get_column_letter(col_index)
            print(f"  ğŸ“ ë°ì´í„° ì…ë ¥ ìœ„ì¹˜: {col_letter}ì—´")
            
            # í—¤ë” ì •ë³´ ì—…ë°ì´íŠ¸
            report_date = datetime.now().strftime('%Y-%m-%d')
            quarter_info = self._get_quarter_info()
            
            # ëª¨ë“  ì£¼ì„ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì—ì„œ ì¤€ë¹„
            all_notes_account_data, all_notes_value_data = self._prepare_notes_data_for_batch_update(wb, notes_type)
            
            # ë°°ì¹˜ ì—…ë°ì´íŠ¸
            print(f"  ğŸš€ ì£¼ì„ ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì‹œì‘...")
            
            # í—¤ë” ì •ë³´
            header_range = f'{col_letter}1:{col_letter}2'
            header_data = [[quarter_info], [report_date]]
            sheet.update(values=header_data, range_name=header_range)
            print(f"    âœ… í—¤ë” ì •ë³´ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            
            # Lì—´ ì£¼ì„ í•­ëª©ëª…
            if all_notes_account_data:
                account_range = f'L7:L{6 + len(all_notes_account_data)}'
                sheet.update(values=all_notes_account_data, range_name=account_range)
                print(f"    âœ… Lì—´ ì£¼ì„ í•­ëª© ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            
            time.sleep(2)
            
            # Mì—´ ì£¼ì„ ê°’
            if all_notes_value_data:
                value_range = f'{col_letter}7:{col_letter}{6 + len(all_notes_value_data)}'
                sheet.update(values=all_notes_value_data, range_name=value_range)
                print(f"    âœ… {col_letter}ì—´ ì£¼ì„ ê°’ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            
            print(f"  âœ… XBRL ì£¼ì„ Archive ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ XBRL ì£¼ì„ Archive ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")

    def _prepare_notes_data_for_batch_update(self, wb, notes_type):
        """ì£¼ì„ ë°ì´í„°ë¥¼ ë°°ì¹˜ ì—…ë°ì´íŠ¸ìš©ìœ¼ë¡œ ì¤€ë¹„ (ê°œì„ ëœ ë¡œì§)"""
        try:
            print(f"  ğŸ”„ ì£¼ì„ ë°°ì¹˜ ì—…ë°ì´íŠ¸ìš© ë°ì´í„° ì¤€ë¹„ ì¤‘... ({notes_type})")
            
            # ì „ì²´ ì‹œíŠ¸ ëª©ë¡ ì¶œë ¥
            print(f"    ğŸ“‹ ì „ì²´ ì‹œíŠ¸ ëª©ë¡: {wb.sheetnames}")
            
            # ê°œì„ ëœ ì£¼ì„ ì‹œíŠ¸ ì°¾ê¸° ë¡œì§
            target_sheets = self._find_notes_sheets(wb, notes_type)
            
            print(f"    ğŸ“„ {notes_type} ì£¼ì„ ì‹œíŠ¸ {len(target_sheets)}ê°œ ë°œê²¬: {target_sheets}")
            
            # ì „ì²´ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ ë°°ì—´ë¡œ í†µí•©
            all_notes_account_data = []
            all_notes_value_data = []
            
            # ê° ì£¼ì„ ì‹œíŠ¸ì˜ ë°ì´í„° ì¶”ì¶œ ë° ë°°ì¹˜
            for sheet_name in sorted(target_sheets):
                sheet_data = self._extract_notes_sheet_data_improved(wb[sheet_name], sheet_name)
                if sheet_data:
                    # ì‹œíŠ¸ ì œëª© ì¶”ê°€
                    all_notes_account_data.append([f"===== {sheet_data['title']} ====="])
                    all_notes_value_data.append([''])
                    
                    # ê° í•­ëª©ë“¤ ë°°ì¹˜
                    for item in sheet_data['items']:
                        if item.get('is_category'):
                            display_name = item['name']
                        elif 'display_name' in item:
                            display_name = item['display_name']
                        else:
                            original_name = item.get('original_name', item['name'])
                            indent_level = item.get('indent_level', 0)
                            
                            if indent_level > 0:
                                display_name = "  " * indent_level + "â”” " + original_name
                            else:
                                display_name = original_name
                        
                        all_notes_account_data.append([display_name])
                        all_notes_value_data.append([item['formatted_value']])
                    
                    # êµ¬ë¶„ì„ ìœ„í•œ ë¹ˆ í–‰ ì¶”ê°€
                    all_notes_account_data.append([''])
                    all_notes_value_data.append([''])
            
            # í†µê³„ ì¶œë ¥
            total_items = len([row for row in all_notes_account_data if row[0] and not row[0].startswith('=')])
            print(f"    ğŸ“Š ì´ ì£¼ì„ í•­ëª©: {total_items}ê°œ")
            
            return all_notes_account_data, all_notes_value_data
            
        except Exception as e:
            print(f"  âŒ ì£¼ì„ ë°°ì¹˜ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {str(e)}")
            return [], []

    def _find_notes_sheets(self, wb, notes_type):
        """ì£¼ì„ ì‹œíŠ¸ë¥¼ ì°¾ëŠ” ê°œì„ ëœ ë¡œì§ (D8/U8 ê·œì¹™ ì ìš©)"""
        target_sheets = []
        
        print(f"    ğŸ” {notes_type} ì£¼ì„ ì‹œíŠ¸ ê²€ìƒ‰ ì¤‘...")
        
        for sheet_name in wb.sheetnames:
            if sheet_name in ['Index', 'ê³µì‹œê¸°ë³¸ì •ë³´']:
                continue
            
            is_target_sheet = False
            
            # ì£¼ì„ ì‹œíŠ¸ ëª…ëª… ê·œì¹™ ì²´í¬: D8/U8ë¡œ ì‹œì‘í•˜ê³  ì—°ê²°(0)/ë³„ë„(5)ë¡œ ëë‚¨
            if notes_type == 'consolidated':
                # ì—°ê²°: D8xxx0 ë˜ëŠ” U8xxx0
                if (sheet_name.startswith('D8') or sheet_name.startswith('U8')) and sheet_name.endswith('0'):
                    is_target_sheet = True
                    print(f"      âœ… ì—°ê²° ì£¼ì„ ì‹œíŠ¸ ë°œê²¬: {sheet_name}")
            else:  # standalone
                # ë³„ë„: D8xxx5 ë˜ëŠ” U8xxx5
                if (sheet_name.startswith('D8') or sheet_name.startswith('U8')) and sheet_name.endswith('5'):
                    is_target_sheet = True
                    print(f"      âœ… ë³„ë„ ì£¼ì„ ì‹œíŠ¸ ë°œê²¬: {sheet_name}")
            
            # ì¶”ê°€: ë‚´ìš© ê¸°ë°˜ ì²´í¬ (ìœ„ ê·œì¹™ì— ë§ì§€ ì•Šì§€ë§Œ ì£¼ì„ì¼ ê°€ëŠ¥ì„±ì´ ìˆëŠ” ì‹œíŠ¸)
            if not is_target_sheet:
                # ì‹œíŠ¸ëª…ì— 'ì£¼ì„'ì´ ëª…ì‹œì ìœ¼ë¡œ í¬í•¨ëœ ê²½ìš°
                if 'ì£¼ì„' in sheet_name or 'Notes' in sheet_name or 'Note' in sheet_name:
                    worksheet = wb[sheet_name]
                    sheet_title = self._get_sheet_title(worksheet)
                    
                    if notes_type == 'consolidated':
                        if 'ì—°ê²°' in sheet_title or ('ë³„ë„' not in sheet_title and not sheet_name.endswith('5')):
                            is_target_sheet = True
                            print(f"      âœ… ë‚´ìš© ê¸°ë°˜ ì—°ê²° ì£¼ì„ ì‹œíŠ¸: {sheet_name}")
                    else:
                        if 'ë³„ë„' in sheet_title or sheet_name.endswith('5'):
                            is_target_sheet = True
                            print(f"      âœ… ë‚´ìš© ê¸°ë°˜ ë³„ë„ ì£¼ì„ ì‹œíŠ¸: {sheet_name}")
            
            if is_target_sheet:
                target_sheets.append(sheet_name)
        
        return target_sheets

    def _extract_notes_sheet_data_improved(self, worksheet, sheet_name):
        """ê°œë³„ ì£¼ì„ ì‹œíŠ¸ì—ì„œ ë°ì´í„° ì¶”ì¶œ (ê¸´ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ê°œì„ )"""
        try:
            sheet_data = {
                'title': sheet_name,
                'items': []
            }
            
            print(f"\n      ğŸ” {sheet_name} ì£¼ì„ ì‹œíŠ¸ ë¶„ì„ ì¤‘...")
            
            # ì „ì²´ ì‹œíŠ¸ ìŠ¤ìº”
            max_row = min(worksheet.max_row, 1000)
            max_col = min(worksheet.max_column, 20)
            
            # ëª¨ë“  ì…€ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œ
            all_data = []
            for row in worksheet.iter_rows(min_row=1, max_row=max_row, min_col=1, max_col=max_col, values_only=True):
                all_data.append(list(row))
            
            print(f"      ğŸ“Š ì‹œíŠ¸ í¬ê¸°: {len(all_data)}í–‰ x {max_col}ì—´")
            
            # í˜„ì¬ ì¤‘ë¶„ë¥˜
            current_category = ""
            current_subcategory = ""
            last_item = None  # ë§ˆì§€ë§‰ìœ¼ë¡œ ì¶”ê°€í•œ í•­ëª©
            
            for row_idx, row in enumerate(all_data):
                if not row or not any(row):  # ë¹ˆ í–‰ ê±´ë„ˆë›°ê¸°
                    continue
                
                # ì²« ë²ˆì§¸ ë¹„ì–´ìˆì§€ ì•Šì€ ì…€ì˜ ìœ„ì¹˜ì™€ ë‚´ìš© ì°¾ê¸°
                first_text = None
                first_col = -1
                text_positions = []  # (ì—´ë²ˆí˜¸, í…ìŠ¤íŠ¸) ìŒ ì €ì¥
                
                for col_idx, cell in enumerate(row):
                    if cell and str(cell).strip():
                        text = str(cell).strip()
                        text_positions.append((col_idx, text))
                        if first_text is None:
                            first_text = text
                            first_col = col_idx
                
                if not first_text or len(first_text) < 2:
                    continue
                
                # ì œì™¸í•  íŒ¨í„´ (ë‹¨ìœ„ í‘œì‹œ ë“±)
                if any(skip in first_text for skip in ['(ë‹¨ìœ„', 'ë‹¨ìœ„:', 'Index', 'Sheet']):
                    continue
                
                # ëŒ€ê´„í˜¸ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ í…ìŠ¤íŠ¸ëŠ” ë¶„ë¥˜ëª…ìœ¼ë¡œ ì²˜ë¦¬
                if first_text.startswith('[') and first_text.endswith(']'):
                    category_name = first_text[1:-1]  # ëŒ€ê´„í˜¸ ì œê±°
                    current_category = category_name
                    current_subcategory = ""  # ìƒˆ ì¤‘ë¶„ë¥˜ì‹œ í•˜ìœ„ë¶„ë¥˜ ì´ˆê¸°í™”
                    
                    sheet_data['items'].append({
                        'name': f"[ì¤‘ë¶„ë¥˜] {category_name}",
                        'value': None,
                        'formatted_value': '',
                        'category': category_name,
                        'is_category': True,
                        'original_name': first_text
                    })
                    last_item = None  # ì¹´í…Œê³ ë¦¬ ë³€ê²½ì‹œ ë¦¬ì…‹
                    continue
                
                # ê¸´ í…ìŠ¤íŠ¸ íŒë³„ (50ì ì´ìƒ)
                is_long_text = len(first_text) > 50
                text_pattern = self._analyze_text_pattern(first_text)
                
                # ê¸´ í…ìŠ¤íŠ¸ì´ê±°ë‚˜ ì„¤ëª…ë¬¸ íŒ¨í„´ì´ê³ , ë°”ë¡œ ì´ì „ì— ì§§ì€ í•­ëª©ëª…ì´ ìˆëŠ” ê²½ìš°
                if (is_long_text or text_pattern == 'description') and last_item and not last_item.get('is_category'):
                    # ì´ì „ í•­ëª©ì˜ ê°’ìœ¼ë¡œ ì²˜ë¦¬
                    if last_item.get('value'):
                        # ì´ë¯¸ ê°’ì´ ìˆìœ¼ë©´ ì¶”ê°€
                        existing_value = str(last_item['value'])
                        last_item['value'] = existing_value + "\n" + first_text
                    else:
                        # ê°’ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ì„¤ì •
                        last_item['value'] = first_text
                        last_item['value_type'] = 'text'
                    
                    # formatted_value ì—…ë°ì´íŠ¸
                    last_item['formatted_value'] = self._format_notes_value(last_item['value'], 'text')
                    continue
                
                # Aì—´ì´ ë¹„ì–´ìˆê³  Bì—´(ë˜ëŠ” ê·¸ ì´í›„)ì— í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš° - ë“¤ì—¬ì“°ê¸°ëœ í•­ëª©
                if first_col > 0:
                    # ë“¤ì—¬ì“°ê¸°ëœ í•­ëª©ìœ¼ë¡œ ì²˜ë¦¬
                    indent_level = first_col
                    
                    # ê¸´ í…ìŠ¤íŠ¸ì´ê³  ë§ˆì§€ë§‰ í•­ëª©ì´ ìˆìœ¼ë©´ ê·¸ í•­ëª©ì˜ ê°’ìœ¼ë¡œ ì²˜ë¦¬
                    if (is_long_text or text_pattern == 'description') and last_item and not last_item.get('is_category'):
                        if last_item.get('value'):
                            existing_value = str(last_item['value'])
                            last_item['value'] = existing_value + "\n" + ("  " * indent_level) + first_text
                        else:
                            last_item['value'] = ("  " * indent_level) + first_text
                            last_item['value_type'] = 'text'
                        
                        last_item['formatted_value'] = self._format_notes_value(last_item['value'], 'text')
                        continue
                    
                    # ì¼ë°˜ì ì¸ ë“¤ì—¬ì“°ê¸° í•­ëª© ì²˜ë¦¬
                    value = None
                    value_type = None
                    
                    # ê°™ì€ í–‰ì—ì„œ ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸ ì´í›„ì˜ ê°’ ì°¾ê¸°
                    for i, (col_idx, text) in enumerate(text_positions):
                        if col_idx == first_col and i < len(text_positions) - 1:
                            # ë‹¤ìŒ í•­ëª©ì´ ê°’ì¼ ê°€ëŠ¥ì„±
                            next_col, next_text = text_positions[i + 1]
                            value, value_type = self._extract_cell_value(next_text)
                            if value is not None:
                                break
                    
                    # ê°’ì„ ëª» ì°¾ì•˜ìœ¼ë©´ ì²« í…ìŠ¤íŠ¸ ì´í›„ì˜ ëª¨ë“  ì…€ í™•ì¸
                    if value is None:
                        for col_idx in range(first_col + 1, len(row)):
                            if row[col_idx] is not None:
                                value, value_type = self._extract_cell_value(row[col_idx])
                                if value is not None:
                                    break
                    
                    # ë“¤ì—¬ì“°ê¸° í‘œì‹œì™€ í•¨ê»˜ í•­ëª© ì¶”ê°€
                    display_name = "  " * indent_level + "â”” " + first_text
                    unique_name = f"{current_category}_{current_subcategory}_{first_text}" if current_subcategory else f"{current_category}_{first_text}"
                    
                    new_item = {
                        'name': unique_name,
                        'original_name': first_text,
                        'display_name': display_name,
                        'value': value,
                        'formatted_value': self._format_notes_value(value, value_type) if value is not None else '',
                        'category': current_category,
                        'subcategory': current_subcategory,
                        'is_category': False,
                        'row_number': row_idx + 1,
                        'value_type': value_type,
                        'indent_level': indent_level
                    }
                    sheet_data['items'].append(new_item)
                    last_item = new_item
                else:
                    # Aì—´ì— ìˆëŠ” í•­ëª© (ë“¤ì—¬ì“°ê¸° ì—†ìŒ)
                    # í•˜ìœ„ ë¶„ë¥˜ì¼ ê°€ëŠ¥ì„± ì²´í¬
                    is_subcategory = False
                    
                    # ë‹¤ìŒ í–‰ë“¤ì´ ë“¤ì—¬ì“°ê¸°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                    if row_idx + 1 < len(all_data) and not is_long_text and text_pattern != 'description':
                        next_rows_indented = 0
                        for check_idx in range(row_idx + 1, min(row_idx + 6, len(all_data))):
                            if check_idx < len(all_data):
                                check_row = all_data[check_idx]
                                # Aì—´ì´ ë¹„ì–´ìˆê³  Bì—´ ì´í›„ì— ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
                                if check_row and (not check_row[0] or not str(check_row[0]).strip()):
                                    for col in range(1, min(5, len(check_row))):
                                        if check_row[col] and str(check_row[col]).strip():
                                            next_rows_indented += 1
                                            break
                        
                        if next_rows_indented >= 2:
                            is_subcategory = True
                            current_subcategory = first_text
                    
                    if is_subcategory:
                        # í•˜ìœ„ ë¶„ë¥˜ë¡œ ì²˜ë¦¬
                        new_item = {
                            'name': f"[í•˜ìœ„ë¶„ë¥˜] {first_text}",
                            'value': None,
                            'formatted_value': '',
                            'category': current_category,
                            'subcategory': first_text,
                            'is_category': True,
                            'is_subcategory': True,
                            'original_name': first_text
                        }
                        sheet_data['items'].append(new_item)
                        last_item = new_item
                    else:
                        # ì¼ë°˜ í•­ëª©ìœ¼ë¡œ ì²˜ë¦¬
                        # ê°’ ì°¾ê¸°
                        value = None
                        value_type = None
                        
                        # ê°™ì€ í–‰ì˜ ë‹¤ìŒ ì—´ë“¤ì—ì„œ ê°’ ì°¾ê¸°
                        for col_idx in range(first_col + 1, len(row)):
                            if row[col_idx] is not None:
                                value, value_type = self._extract_cell_value(row[col_idx])
                                if value is not None:
                                    break
                        
                        unique_name = f"{current_category}_{current_subcategory}_{first_text}" if current_subcategory else f"{current_category}_{first_text}" if current_category else first_text
                        
                        new_item = {
                            'name': unique_name,
                            'original_name': first_text,
                            'value': value,
                            'formatted_value': self._format_notes_value(value, value_type) if value is not None else '',
                            'category': current_category,
                            'subcategory': current_subcategory,
                            'is_category': False,
                            'row_number': row_idx + 1,
                            'value_type': value_type,
                            'indent_level': 0,
                            'text_length': len(first_text)  # í…ìŠ¤íŠ¸ ê¸¸ì´ ì €ì¥
                        }
                        sheet_data['items'].append(new_item)
                        last_item = new_item
            
            # ê²°ê³¼ ìš”ì•½
            if sheet_data['items']:
                category_count = len([item for item in sheet_data['items'] if item.get('is_category') and not item.get('is_subcategory')])
                subcategory_count = len([item for item in sheet_data['items'] if item.get('is_subcategory')])
                value_count = len([item for item in sheet_data['items'] if item.get('value') is not None])
                text_count = len([item for item in sheet_data['items'] if item.get('value_type') == 'text'])
                number_count = len([item for item in sheet_data['items'] if item.get('value_type') == 'number'])
                
                print(f"      âœ… ì¶”ì¶œ ì™„ë£Œ: ì´ {len(sheet_data['items'])}ê°œ í•­ëª©")
                print(f"         - ì¤‘ë¶„ë¥˜: {category_count}ê°œ")
                print(f"         - í•˜ìœ„ë¶„ë¥˜: {subcategory_count}ê°œ") 
                print(f"         - ê°’ ìˆìŒ: {value_count}ê°œ (ìˆ«ì: {number_count}, í…ìŠ¤íŠ¸: {text_count})")
            
            return sheet_data if sheet_data['items'] else None
            
        except Exception as e:
            print(f"      âŒ ì£¼ì„ ì‹œíŠ¸ {sheet_name} ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            import traceback
            traceback.print_exc()
            return None

    def _analyze_text_pattern(self, text):
        """í…ìŠ¤íŠ¸ íŒ¨í„´ ë¶„ì„í•˜ì—¬ í•­ëª©ëª…ì¸ì§€ ê¸´ ì„¤ëª…ì¸ì§€ íŒë‹¨"""
        # í•­ëª©ëª… íŒ¨í„´
        item_patterns = [
            r'^\d+\.',  # ìˆ«ìë¡œ ì‹œì‘ (1. 2. ë“±)
            r'^\([ê°€-í£]\)',  # (ê°€) (ë‚˜) ë“±
            r'^\[[ê°€-í£]\]',  # [ê°€] [ë‚˜] ë“±
            r'^[â‘ -â‘©]',  # ì› ìˆ«ì
            r'^[ê°€-í£]{2,10}  # ì§§ì€ í•œê¸€ ë‹¨ì–´
        ]
        
        # ì„¤ëª… íŒ¨í„´
        description_patterns = [
            r'[ì€ëŠ”ì´ê°€ì„ë¥¼ì—ì„œì˜ë¡œì™€ê³¼]',  # ì¡°ì‚¬ê°€ ë§ì´ í¬í•¨ëœ ê²½ìš°
            r'[í–ˆìŠµë‹ˆë‹¤|í•©ë‹ˆë‹¤|ë©ë‹ˆë‹¤|ìˆìŠµë‹ˆë‹¤]',  # ë¬¸ì¥ ì¢…ê²°ì–´
            r'[í•˜ì˜€ê³ |í•˜ì˜€ìœ¼ë©°|ë˜ì—ˆê³ |ë˜ì—ˆìœ¼ë©°]'  # ì—°ê²°ì–´
        ]
        
        # í•­ëª©ëª… íŒ¨í„´ ì²´í¬
        for pattern in item_patterns:
            if re.match(pattern, text):
                return 'item'
        
        # ì„¤ëª… íŒ¨í„´ ì²´í¬
        description_score = 0
        for pattern in description_patterns:
            if re.search(pattern, text):
                description_score += 1
        
        # ê¸¸ì´ì™€ ì„¤ëª… ì ìˆ˜ë¡œ íŒë‹¨
        if len(text) > 50 and description_score >= 2:
            return 'description'
        elif len(text) > 100:
            return 'description'
        
        return 'item'

    def _extract_cell_value(self, cell_value):
        """ì…€ ê°’ì—ì„œ ì‹¤ì œ ê°’ê³¼ íƒ€ì… ì¶”ì¶œ"""
        if cell_value is None:
            return None, None
            
        # ìˆ«ìì¸ ê²½ìš°
        if isinstance(cell_value, (int, float)):
            return cell_value, 'number'
        
        # ë¬¸ìì—´ì¸ ê²½ìš°
        elif isinstance(cell_value, str):
            str_val = str(cell_value).strip()
            if not str_val or str_val == '-':
                return None, None
                
            # ìˆ«ì ë³€í™˜ ì‹œë„
            try:
                clean_num = str_val.replace(',', '').replace('(', '-').replace(')', '').strip()
                if clean_num and clean_num != '-' and clean_num.replace('-', '').replace('.', '').isdigit():
                    return float(clean_num), 'number'
            except:
                pass
            
            # í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
            if len(str_val) >= 2:
                return str_val, 'text'
        
        return None, None

    def _format_notes_value(self, value, value_type=None):
        """ì£¼ì„ ê°’ í¬ë§·íŒ… (ìˆ«ì ë° í…ìŠ¤íŠ¸ ì²˜ë¦¬, í™˜ê²½ë³€ìˆ˜ ë‹¨ìœ„ ì ìš©)"""
        try:
            if value is None:
                return ''
            
            # í…ìŠ¤íŠ¸ì¸ ê²½ìš°
            if value_type == 'text' or isinstance(value, str):
                # ê¸´ í…ìŠ¤íŠ¸ëŠ” ì ì ˆíˆ ì˜ë¼ì„œ í‘œì‹œ
                text_value = str(value).strip()
                if len(text_value) > 100:
                    return text_value[:97] + "..."
                else:
                    return text_value
            
            # ìˆ«ìì¸ ê²½ìš° - í™˜ê²½ë³€ìˆ˜ ë‹¨ìœ„ ì ìš©
            elif isinstance(value, (int, float)):
                # í™˜ê²½ë³€ìˆ˜ì—ì„œ ë‹¨ìœ„ ê°€ì ¸ì˜¤ê¸°
                number_unit = os.environ.get('NUMBER_UNIT', 'million')
                
                if number_unit == 'million':  # ë°±ë§Œì›
                    if abs(value) >= 1000000:
                        converted_value = value / 1000000
                        return f"{converted_value:.1f}ë°±ë§Œì›"
                    else:
                        return f"{value:,.0f}"
                
                elif number_unit == 'hundred_million':  # ì–µì›
                    if abs(value) >= 100000000:
                        converted_value = value / 100000000
                        return f"{converted_value:.2f}ì–µì›"
                    elif abs(value) >= 1000000:
                        million_value = value / 1000000
                        return f"{million_value:.1f}ë°±ë§Œì›"
                    else:
                        return f"{value:,.0f}"
                
                elif number_unit == 'billion':  # ì‹­ì–µì›
                    if abs(value) >= 1000000000:
                        converted_value = value / 1000000000
                        return f"{converted_value:.2f}ì‹­ì–µì›"
                    elif abs(value) >= 100000000:
                        hundred_million_value = value / 100000000
                        return f"{hundred_million_value:.1f}ì–µì›"
                    else:
                        return f"{value:,.0f}"
                
                else:  # ê¸°ë³¸ê°’: ë°±ë§Œì›
                    if abs(value) >= 1000000:
                        converted_value = value / 1000000
                        return f"{converted_value:.1f}ë°±ë§Œì›"
                    else:
                        return f"{value:,.0f}"
            
            else:
                return str(value)
                
        except Exception as e:
            print(f"    âš ï¸ ì£¼ì„ ê°’ í¬ë§·íŒ… ì˜¤ë¥˜ ({value}): {str(e)}")
            return str(value) if value else ''

    def _format_number_for_archive(self, value):
        """Archiveìš© ìˆ«ì í¬ë§·íŒ… (í™˜ê²½ë³€ìˆ˜ë¡œ ë‹¨ìœ„ ì„¤ì •)"""
        try:
            if not value:
                return ''
            
            # ìˆ«ì ë³€í™˜
            num = self._clean_number(value)
            if num is None:
                return ''
            
            # í™˜ê²½ë³€ìˆ˜ì—ì„œ ë‹¨ìœ„ ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’: ë°±ë§Œì›)
            number_unit = os.environ.get('NUMBER_UNIT', 'million')
            
            # ë‹¨ìœ„ë³„ ë³€í™˜
            if number_unit == 'million':  # ë°±ë§Œì›
                unit_value = num / 1000000
                unit_suffix = "ë°±ë§Œì›"
            elif number_unit == 'hundred_million':  # ì–µì›
                unit_value = num / 100000000
                unit_suffix = "ì–µì›"
            elif number_unit == 'billion':  # ì‹­ì–µì›
                unit_value = num / 1000000000
                unit_suffix = "ì‹­ì–µì›"
            else:  # ê¸°ë³¸ê°’: ë°±ë§Œì›
                unit_value = num / 1000000
                unit_suffix = "ë°±ë§Œì›"
            
            # ì†Œìˆ˜ì  ìë¦¬ ê²°ì •
            if abs(unit_value) >= 1000:
                formatted = f"{unit_value:.0f}"  # 1000 ì´ìƒì€ ì •ìˆ˜
            elif abs(unit_value) >= 100:
                formatted = f"{unit_value:.1f}"  # 100 ì´ìƒì€ ì†Œìˆ˜ì  1ìë¦¬
            else:
                formatted = f"{unit_value:.2f}"  # 100 ë¯¸ë§Œì€ ì†Œìˆ˜ì  2ìë¦¬
            
            # ë‹¨ìœ„ í‘œì‹œ ì—¬ë¶€ (ì²˜ìŒ í•œ ë²ˆë§Œ í‘œì‹œí•˜ë„ë¡ í•  ìˆ˜ë„ ìˆìŒ)
            # return f"{formatted} {unit_suffix}"  # ë‹¨ìœ„ í¬í•¨
            return formatted  # ë‹¨ìœ„ ì œì™¸ (í—¤ë”ì— í‘œì‹œ)
                
        except Exception as e:
            print(f"    âš ï¸ ìˆ«ì í¬ë§·íŒ… ì˜¤ë¥˜ ({value}): {str(e)}")
            return str(value)

    def _clean_number(self, value):
        """ìˆ«ì ê°’ ì •ì œ"""
        try:
            if isinstance(value, (int, float)):
                return float(value)
            
            str_val = str(value).replace(',', '').replace('(', '-').replace(')', '').strip()
            if not str_val or str_val == '-':
                return None
            return float(str_val)
        except:
            return None

    def _get_quarter_info(self):
        """ë³´ê³ ì„œ ê¸°ì¤€ ë¶„ê¸° ì •ë³´ ë°˜í™˜"""
        try:
            if self.current_report is not None and hasattr(self.current_report, 'get'):
                if hasattr(self.current_report, 'iloc'):
                    report_name = self.current_report.get('report_nm', '')
                else:
                    report_name = self.current_report.get('report_nm', '')
                
                if report_name:
                    print(f"  ğŸ“… ë³´ê³ ì„œ ë¶„ì„: {report_name}")
                    
                    import re
                    
                    # íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ë¶„ê¸° ì •ë³´ ì¶”ì¶œ
                    if '1ë¶„ê¸°' in str(report_name):
                        current_year = datetime.now().year
                        quarter_text = f"1Q{str(current_year)[2:]}"
                        return quarter_text
                    elif 'ë°˜ê¸°' in str(report_name) or '2ë¶„ê¸°' in str(report_name):
                        current_year = datetime.now().year
                        quarter_text = f"2Q{str(current_year)[2:]}"
                        return quarter_text
                    elif '3ë¶„ê¸°' in str(report_name):
                        current_year = datetime.now().year
                        quarter_text = f"3Q{str(current_year)[2:]}"
                        return quarter_text
                    
                    # ë‚ ì§œ íŒ¨í„´ ë§¤ì¹­
                    date_pattern1 = re.search(r'\((\d{4})\.(\d{2})\)', str(report_name))
                    date_pattern2 = re.search(r'(\d{4})ë…„\s*(\d{1,2})ì›”', str(report_name))
                    
                    year, month = None, None
                    
                    if date_pattern1:
                        year, month = date_pattern1.groups()
                        month = int(month)
                    elif date_pattern2:
                        year, month = date_pattern2.groups()
                        month = int(month)
                    
                    if year and month:
                        if month <= 3:
                            quarter = 1
                        elif month <= 6:
                            quarter = 2
                        elif month <= 9:
                            quarter = 3
                        else:
                            quarter = 4
                        
                        quarter_text = f"{quarter}Q{year[2:]}"
                        return quarter_text
        
        except Exception as e:
            print(f"    âš ï¸ ë¶„ê¸° ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        # ê¸°ë³¸ê°’: í˜„ì¬ ë‚ ì§œ ê¸°ì¤€
        now = datetime.now()
        quarter = (now.month - 1) // 3 + 1
        year = str(now.year)[2:]
        default_quarter = f"{quarter}Q{year}"
        return default_quarter

    def _get_sheet_title(self, worksheet):
        """ì‹œíŠ¸ì˜ ì œëª© ì°¾ê¸° (ì²˜ìŒ 10í–‰ì—ì„œ)"""
        try:
            for row_idx in range(1, min(11, worksheet.max_row + 1)):
                for col_idx in range(1, min(4, worksheet.max_column + 1)):
                    cell = worksheet.cell(row=row_idx, column=col_idx)
                    if cell.value and isinstance(cell.value, str):
                        value = str(cell.value).strip()
                        if len(value) > 5 and ('ì¬ë¬´ìƒíƒœí‘œ' in value or 'ì†ìµê³„ì‚°ì„œ' in value or 
                                               'í˜„ê¸ˆíë¦„í‘œ' in value or 'ìë³¸ë³€ë™í‘œ' in value or
                                               'í¬ê´„ì†ìµ' in value or 'ì£¼ì„' in value):
                            return value
            return ""
        except:
            return ""

    def _get_column_letter(self, col_index):
        """ì»¬ëŸ¼ ì¸ë±ìŠ¤ë¥¼ ë¬¸ìë¡œ ë³€í™˜ (0-based)"""
        result = ""
        num = col_index + 1  # 1-basedë¡œ ë³€í™˜
        while num > 0:
            num, remainder = divmod(num - 1, 26)
            result = chr(65 + remainder) + result
        return result

    def _send_telegram_message(self, message):
        """í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì „ì†¡"""
        try:
            if self.telegram_bot_token and self.telegram_channel_id:
                import requests
                url = f"https://api.telegram.org/bot{self.telegram_bot_token}/sendMessage"
                data = {
                    "chat_id": self.telegram_channel_id,
                    "text": message,
                    "parse_mode": "HTML"
                }
                requests.post(url, data=data)
                print("ğŸ“± í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì „ì†¡ ì™„ë£Œ")
        except Exception as e:
            print(f"ğŸ“± í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨: {str(e)}")

    def _cleanup_downloads(self):
        """ë‹¤ìš´ë¡œë“œ í´ë” ì •ë¦¬"""
        try:
            # Archive ì—…ë°ì´íŠ¸ê°€ ì™„ë£Œëœ í›„ì—ë§Œ ì •ë¦¬
            if os.path.exists(self.download_dir) and self.results.get('xbrl', {}).get('excel_files'):
                # Excel íŒŒì¼ë“¤ë§Œ ë‚¨ê¸°ê³  ë‹¤ë¥¸ íŒŒì¼ë“¤ ì •ë¦¬
                for file in os.listdir(self.download_dir):
                    file_path = os.path.join(self.download_dir, file)
                    if file_path not in self.results['xbrl']['downloaded_files']:
                        os.remove(file_path)
                
                # Archive ì—…ë°ì´íŠ¸ ì™„ë£Œ í›„ ì „ì²´ í´ë” ì‚­ì œ
                if os.environ.get('DELETE_AFTER_ARCHIVE', 'true').lower() == 'true':
                    shutil.rmtree(self.download_dir)
                    print("ğŸ§¹ ë‹¤ìš´ë¡œë“œ í´ë” ì •ë¦¬ ì™„ë£Œ")
                else:
                    print("ğŸ“ ë‹¤ìš´ë¡œë“œ íŒŒì¼ ë³´ì¡´ ì¤‘")
        except Exception as e:
            print(f"âš ï¸ ë‹¤ìš´ë¡œë“œ í´ë” ì •ë¦¬ ì‹¤íŒ¨: {str(e)}")

    def _print_summary(self):
        """ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½"""
        print("\n" + "="*50)
        print("ğŸ“Š ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½")
        print("="*50)
        print(f"ì „ì²´ ë³´ê³ ì„œ: {self.results['total_reports']}ê°œ")
        print(f"XBRL ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {len(self.results['xbrl']['downloaded_files'])}ê°œ")
        print(f"XBRL ì—…ë¡œë“œëœ ì‹œíŠ¸: {len(self.results['xbrl']['uploaded_sheets'])}ê°œ")
        print(f"XBRL ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {len(self.results['xbrl']['failed_downloads'])}ê°œ")
        print(f"XBRL ì—…ë¡œë“œ ì‹¤íŒ¨: {len(self.results['xbrl']['failed_uploads'])}ê°œ")
        print(f"HTML ì²˜ë¦¬ëœ ì‹œíŠ¸: {len(self.results['html']['processed_sheets'])}ê°œ")
        print(f"HTML ì‹¤íŒ¨: {len(self.results['html']['failed_sheets'])}ê°œ")
        
        # í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì „ì†¡
        if self.telegram_bot_token and self.telegram_channel_id:
            self._send_telegram_summary()

    def _send_telegram_summary(self):
        """í…”ë ˆê·¸ë¨ ìš”ì•½ ë©”ì‹œì§€ ì „ì†¡"""
        try:
            import requests
            
            message = (
                f"ğŸ“Š DART í†µí•© ì—…ë°ì´íŠ¸ ì™„ë£Œ\n\n"
                f"â€¢ ì¢…ëª©: {self.company_name} ({self.corp_code})\n"
                f"â€¢ ì²˜ë¦¬ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                f"â€¢ ì „ì²´ ë³´ê³ ì„œ: {self.results['total_reports']}ê°œ\n"
                f"â€¢ XBRL ë‹¤ìš´ë¡œë“œ: {len(self.results['xbrl']['downloaded_files'])}ê°œ\n"
                f"â€¢ XBRL ì—…ë¡œë“œ: {len(self.results['xbrl']['uploaded_sheets'])}ê°œ\n"
                f"â€¢ HTML ì²˜ë¦¬: {len(self.results['html']['processed_sheets'])}ê°œ"
            )
            
            url = f"https://api.telegram.org/bot{self.telegram_bot_token}/sendMessage"
            data = {
                "chat_id": self.telegram_channel_id,
                "text": message,
                "parse_mode": "HTML"
            }
            requests.post(url, data=data)
            print("ğŸ“± í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì „ì†¡ ì™„ë£Œ")
            
        except Exception as e:
            print(f"ğŸ“± í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨: {str(e)}")


def load_company_config():
    """íšŒì‚¬ ì„¤ì • ë¡œë“œ"""
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì½ê¸°
    corp_code = os.environ.get('COMPANY_CORP_CODE', '307950')
    company_name = os.environ.get('COMPANY_NAME', 'í˜„ëŒ€ì˜¤í† ì—ë²„')
    spreadsheet_var = os.environ.get('COMPANY_SPREADSHEET_VAR', 'AUTOEVER_SPREADSHEET_ID')
    
    return {
        'corp_code': corp_code,
        'company_name': company_name,
        'spreadsheet_var': spreadsheet_var
    }


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        # Playwright ì„¤ì¹˜ í™•ì¸
        print("ğŸ”§ Playwright ë¸Œë¼ìš°ì € ì„¤ì¹˜ í™•ì¸...")
        os.system("playwright install chromium")
        
        # íšŒì‚¬ ì„¤ì • ë¡œë“œ
        company_config = load_company_config()
        
        print(f"ğŸ¤– DART í†µí•© ì—…ë°ì´í„° ì‹œìŠ¤í…œ")
        print(f"ğŸ¢ ëŒ€ìƒ ê¸°ì—…: {company_config['company_name']} ({company_config['corp_code']})")
        
        # í†µí•© ì—…ë°ì´í„° ì‹¤í–‰
        updater = DartDualUpdater(company_config)
        updater.run()
        
        print("\nâœ… ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        raise


if __name__ == "__main__":
    main()
