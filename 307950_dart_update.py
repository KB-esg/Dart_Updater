import os
from datetime import datetime, timedelta
import json
import time
import re
import gspread
from google.oauth2.service_account import Credentials
import OpenDartReader
import requests
from bs4 import BeautifulSoup
import pandas as pd
import xml.etree.ElementTree as ET
from urllib.parse import urljoin, urlparse
import zipfile
import io

# HTML í…Œì´ë¸” íŒŒì„œ ëŒ€ì•ˆ êµ¬í˜„
try:
    from html_table_parser import parser_functions as parser
    HTML_PARSER_AVAILABLE = True
    print("âœ… html_table_parser ë¡œë“œ ì„±ê³µ")
except ImportError:
    try:
        from html_table_parser_python3 import parser_functions as parser
        HTML_PARSER_AVAILABLE = True
        print("âœ… html_table_parser_python3 ë¡œë“œ ì„±ê³µ")
    except ImportError:
        HTML_PARSER_AVAILABLE = False
        print("âš ï¸ HTML íŒŒì„œ íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ë‚´ì¥ íŒŒì„œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

class XBRLDartReportUpdater:
    """XBRL ê¸°ë°˜ Dart ë³´ê³ ì„œ ì—…ë°ì´í„° (ê²¬ê³ í•œ HTML íŒŒì‹± í¬í•¨)"""
    
    TARGET_SHEETS = [
        'I. íšŒì‚¬ì˜ ê°œìš”', 'II. ì‚¬ì—…ì˜ ë‚´ìš©', '1. ì‚¬ì—…ì˜ ê°œìš”', '2. ì£¼ìš” ì œí’ˆ ë° ì„œë¹„ìŠ¤',
        '3. ì›ì¬ë£Œ ë° ìƒì‚°ì„¤ë¹„', '4. ë§¤ì¶œ ë° ìˆ˜ì£¼ìƒí™©', '5. ìœ„í—˜ê´€ë¦¬ ë° íŒŒìƒê±°ë˜',
        '6. ì£¼ìš”ê³„ì•½ ë° ì—°êµ¬í™œë™', '7. ê¸°íƒ€ ì°¸ê³  ì‚¬í•­', '1. ìš”ì•½ì¬ë¬´ì •ë³´',
        '2. ì—°ê²°ì¬ë¬´ì œí‘œ', '3. ì—°ê²°ì¬ë¬´ì œí‘œ ì£¼ì„', '4. ì¬ë¬´ì œí‘œ', '5. ì¬ë¬´ì œí‘œ ì£¼ì„',
        '6. ë°°ë‹¹ì— ê´€í•œ ì‚¬í•­', '8. ê¸°íƒ€ ì¬ë¬´ì— ê´€í•œ ì‚¬í•­', 'VII. ì£¼ì£¼ì— ê´€í•œ ì‚¬í•­',
        'VIII. ì„ì› ë° ì§ì› ë“±ì— ê´€í•œ ì‚¬í•­', 'X. ëŒ€ì£¼ì£¼ ë“±ê³¼ì˜ ê±°ë˜ë‚´ìš©',
        'XI. ê·¸ ë°–ì— íˆ¬ìì ë³´í˜¸ë¥¼ ìœ„í•˜ì—¬ í•„ìš”í•œ ì‚¬í•­'
    ]

    def __init__(self, corp_code, spreadsheet_var_name, company_name):
        """ì´ˆê¸°í™”"""
        self.corp_code = corp_code
        self.company_name = company_name
        self.spreadsheet_var_name = spreadsheet_var_name
        
        # í™˜ê²½ë³€ìˆ˜ í™•ì¸
        print("í™˜ê²½ë³€ìˆ˜ í™•ì¸:")
        required_vars = ['DART_API_KEY', 'GOOGLE_CREDENTIALS', spreadsheet_var_name, 
                        'TELEGRAM_BOT_TOKEN', 'TELEGRAM_CHANNEL_ID']
        for var in required_vars:
            print(f"{var} ì¡´ì¬:", var in os.environ)
        
        if spreadsheet_var_name not in os.environ:
            raise ValueError(f"{spreadsheet_var_name} í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
        self.credentials = self.get_credentials()
        self.gc = gspread.authorize(self.credentials)
        self.dart = OpenDartReader(os.environ['DART_API_KEY'])
        self.workbook = self.gc.open_by_key(os.environ[spreadsheet_var_name])
        self.telegram_bot_token = os.environ.get('TELEGRAM_BOT_TOKEN')
        self.telegram_channel_id = os.environ.get('TELEGRAM_CHANNEL_ID')
        
        # XBRL ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì •ì˜
        self.xbrl_namespaces = {
            'xbrl': 'http://www.xbrl.org/2003/instance',
            'ifrs': 'http://xbrl.ifrs.org/taxonomy/2021-03-24/ifrs',
            'ifrs-full': 'http://xbrl.ifrs.org/taxonomy/2021-03-24/ifrs-full',
            'dart': 'http://dart.fss.or.kr/xbrl/taxonomy/kr-gaap',
            'link': 'http://www.xbrl.org/2003/linkbase',
            'xlink': 'http://www.w3.org/1999/xlink'
        }

    def get_credentials(self):
        """Google Sheets ì¸ì¦ ì„¤ì •"""
        creds_json = json.loads(os.environ['GOOGLE_CREDENTIALS'])
        scopes = [
            'https://www.googleapis.com/auth/spreadsheets',
            'https://www.googleapis.com/auth/drive'
        ]
        return Credentials.from_service_account_info(creds_json, scopes=scopes)

    def parse_html_table_fallback(self, table):
        """ë‚´ì¥ HTML í…Œì´ë¸” íŒŒì„œ (ëŒ€ì•ˆ)"""
        try:
            rows = []
            for tr in table.find_all('tr'):
                row = []
                for cell in tr.find_all(['td', 'th']):
                    # ì…€ ë³‘í•© ì²˜ë¦¬
                    colspan = int(cell.get('colspan', 1))
                    rowspan = int(cell.get('rowspan', 1))
                    
                    # í…ìŠ¤íŠ¸ ì •ë¦¬
                    text = cell.get_text(separator=' ', strip=True)
                    text = re.sub(r'\s+', ' ', text)  # ì—°ì† ê³µë°± ì œê±°
                    
                    row.append(text)
                    
                    # colspan ì²˜ë¦¬ (ë¹ˆ ì…€ ì¶”ê°€)
                    for _ in range(colspan - 1):
                        row.append('')
                
                if row:  # ë¹ˆ í–‰ ì œì™¸
                    rows.append(row)
            
            return rows
            
        except Exception as e:
            print(f"ë‚´ì¥ HTML íŒŒì„œ ì˜¤ë¥˜: {str(e)}")
            return []

    def parse_html_table_robust(self, table):
        """ê²¬ê³ í•œ HTML í…Œì´ë¸” íŒŒì‹±"""
        try:
            # ìš°ì„  ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‹œë„
            if HTML_PARSER_AVAILABLE:
                try:
                    return parser.make2d(table)
                except Exception as e:
                    print(f"ì™¸ë¶€ HTML íŒŒì„œ ì‹¤íŒ¨, ë‚´ì¥ íŒŒì„œë¡œ ì „í™˜: {str(e)}")
            
            # ë‚´ì¥ íŒŒì„œ ì‚¬ìš©
            return self.parse_html_table_fallback(table)
            
        except Exception as e:
            print(f"HTML í…Œì´ë¸” íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
            return []

    def process_html_content(self, worksheet, html_content):
        """HTML ë‚´ìš© ì²˜ë¦¬ ë° ì›Œí¬ì‹œíŠ¸ ì—…ë°ì´íŠ¸ (ê°œì„ ëœ ë²„ì „)"""
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            tables = soup.find_all("table")
            
            worksheet.clear()
            all_data = []
            
            print(f"ë°œê²¬ëœ í…Œì´ë¸” ìˆ˜: {len(tables)}")
            
            for i, table in enumerate(tables):
                print(f"í…Œì´ë¸” {i+1} ì²˜ë¦¬ ì¤‘...")
                
                # ê²¬ê³ í•œ HTML íŒŒì‹± ì‚¬ìš©
                table_data = self.parse_html_table_robust(table)
                
                if table_data:
                    print(f"í…Œì´ë¸” {i+1}: {len(table_data)}í–‰ ì¶”ì¶œ")
                    all_data.extend(table_data)
                    # í…Œì´ë¸” ê°„ êµ¬ë¶„ì„ ìœ„í•œ ë¹ˆ í–‰ ì¶”ê°€
                    all_data.append([''])
                else:
                    print(f"í…Œì´ë¸” {i+1}: ë°ì´í„° ì—†ìŒ")
            
            if all_data:
                # ë§ˆì§€ë§‰ ë¹ˆ í–‰ ì œê±°
                if all_data and all_data[-1] == ['']:
                    all_data.pop()
                
                print(f"ì „ì²´ {len(all_data)}í–‰ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
                
                # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì—…ë¡œë“œ
                BATCH_SIZE = 100
                for i in range(0, len(all_data), BATCH_SIZE):
                    batch = all_data[i:i + BATCH_SIZE]
                    try:
                        # í–‰ ê¸¸ì´ ì •ê·œí™” (ê°€ì¥ ê¸´ í–‰ì— ë§ì¶¤)
                        max_cols = max(len(row) for row in batch) if batch else 0
                        normalized_batch = []
                        for row in batch:
                            normalized_row = row + [''] * (max_cols - len(row))
                            normalized_batch.append(normalized_row)
                        
                        worksheet.append_rows(normalized_batch)
                        print(f"ë°°ì¹˜ ì—…ë¡œë“œ ì™„ë£Œ: {i+1}~{min(i+BATCH_SIZE, len(all_data))} í–‰")
                        
                    except gspread.exceptions.APIError as e:
                        if 'Quota exceeded' in str(e):
                            print("API í• ë‹¹ëŸ‰ ì´ˆê³¼. 60ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                            time.sleep(60)
                            worksheet.append_rows(normalized_batch)
                        else:
                            print(f"API ì˜¤ë¥˜: {str(e)}")
                            raise e
                    except Exception as e:
                        print(f"ë°°ì¹˜ ì—…ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
                        # ê°œë³„ í–‰ìœ¼ë¡œ ì¬ì‹œë„
                        for row in batch:
                            try:
                                worksheet.append_row(row)
                                time.sleep(0.1)  # API ì œí•œ ë°©ì§€
                            except Exception as row_e:
                                print(f"ê°œë³„ í–‰ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(row_e)}")
                                continue
            else:
                print("âš ï¸ ì¶”ì¶œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            print(f"HTML ì½˜í…ì¸  ì²˜ë¦¬ ì¤‘ ì „ì²´ ì˜¤ë¥˜: {str(e)}")
            raise

    def download_xbrl_data(self, rcept_no):
        """XBRL ë°ì´í„° ë‹¤ìš´ë¡œë“œ"""
        print(f"XBRL ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹œì‘: {rcept_no}")
        
        try:
            # ë°©ë²• 1: ì§ì ‘ XBRL íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            download_url = f"https://opendart.fss.or.kr/disclosureinfo/fnltt/dwld/main.do?rcp_no={rcept_no}"
            
            session = requests.Session()
            session.headers.update({
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': 'application/zip, application/xml, text/xml, */*',
                'Referer': 'https://opendart.fss.or.kr/'
            })
            
            response = session.get(download_url, timeout=30)
            response.raise_for_status()
            
            content_type = response.headers.get('content-type', '').lower()
            content_disposition = response.headers.get('content-disposition', '').lower()
            
            # ZIP íŒŒì¼ í™•ì¸
            if ('application/zip' in content_type or 
                'application/x-zip' in content_type or 
                '.zip' in content_disposition):
                print("ZIP íŒŒì¼ ê°ì§€, ì••ì¶• í•´ì œ ì¤‘...")
                return self.extract_xbrl_from_zip(response.content)
            
            # XML íŒŒì¼ í™•ì¸
            elif ('xml' in content_type or 
                  response.content.strip().startswith(b'<?xml')):
                print("XML íŒŒì¼ ê°ì§€")
                return response.content.decode('utf-8')
            
            else:
                print(f"ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼ í˜•ì‹: {content_type}")
                print("XBRL ë·°ì–´ ë°©ì‹ìœ¼ë¡œ ì „í™˜...")
                return self.get_xbrl_from_viewer(rcept_no)
                
        except Exception as e:
            print(f"XBRL ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            print("ë·°ì–´ ë°©ì‹ìœ¼ë¡œ ì „í™˜...")
            return self.get_xbrl_from_viewer(rcept_no)

    def extract_xbrl_from_zip(self, zip_content):
        """ZIP íŒŒì¼ì—ì„œ XBRL ë°ì´í„° ì¶”ì¶œ"""
        try:
            with zipfile.ZipFile(io.BytesIO(zip_content)) as zip_ref:
                file_list = zip_ref.namelist()
                print(f"ZIP íŒŒì¼ ë‚´ìš©: {file_list}")
                
                # XBRL íŒŒì¼ ìš°ì„ ìˆœìœ„ë¡œ ì°¾ê¸°
                xbrl_patterns = [
                    r'.*\.xbrl$',
                    r'.*xbrl.*\.xml$',
                    r'.*_financial.*\.xml$',
                    r'.*\.xml$'
                ]
                
                xbrl_file = None
                for pattern in xbrl_patterns:
                    matching_files = [f for f in file_list if re.match(pattern, f, re.IGNORECASE)]
                    if matching_files:
                        # ê°€ì¥ í° íŒŒì¼ ì„ íƒ
                        xbrl_file = max(matching_files, key=lambda x: zip_ref.getinfo(x).file_size)
                        print(f"XBRL íŒŒì¼ ì„ íƒ: {xbrl_file}")
                        break
                
                if xbrl_file:
                    with zip_ref.open(xbrl_file) as f:
                        content = f.read()
                        # UTF-8 ë˜ëŠ” UTF-8-BOMìœ¼ë¡œ ë””ì½”ë”© ì‹œë„
                        try:
                            return content.decode('utf-8')
                        except UnicodeDecodeError:
                            try:
                                return content.decode('utf-8-sig')
                            except UnicodeDecodeError:
                                return content.decode('euc-kr')
                else:
                    raise ValueError("ZIP íŒŒì¼ì—ì„œ XBRL íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    
        except Exception as e:
            print(f"ZIP íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            raise

    def get_xbrl_from_viewer(self, rcept_no):
        """XBRL ë·°ì–´ì—ì„œ ë°ì´í„° ì¶”ì¶œ (ëŒ€ì•ˆ)"""
        print(f"XBRL ë·°ì–´ ë°©ì‹ìœ¼ë¡œ ë°ì´í„° ì¶”ì¶œ ì‹œë„: {rcept_no}")
        
        try:
            # ë‹¤ì–‘í•œ XBRL ì ‘ê·¼ URL ì‹œë„
            potential_urls = [
                f"https://opendart.fss.or.kr/xbrl/viewer/main.do?rcpNo={rcept_no}",
                f"https://dart.fss.or.kr/dsaf001/main.do?rcpNo={rcept_no}",
                f"https://opendart.fss.or.kr/api/xbrl/{rcept_no}.xml"
            ]
            
            session = requests.Session()
            session.headers.update({
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            })
            
            for url in potential_urls:
                try:
                    print(f"ì‹œë„ ì¤‘: {url}")
                    response = session.get(url, timeout=30)
                    
                    if response.status_code == 200:
                        content_type = response.headers.get('content-type', '')
                        
                        # XML ì‘ë‹µì¸ ê²½ìš°
                        if 'xml' in content_type or response.text.strip().startswith('<?xml'):
                            print(f"XML ë°ì´í„° ë°œê²¬: {url}")
                            return response.text
                        
                        # HTML ë·°ì–´ í˜ì´ì§€ì¸ ê²½ìš° JavaScript ë¶„ì„
                        elif 'html' in content_type:
                            print(f"HTML ë·°ì–´ í˜ì´ì§€ ë¶„ì„: {url}")
                            return self.extract_from_html_viewer(response.text, rcept_no)
                            
                except requests.RequestException as e:
                    print(f"URL {url} ì‹¤íŒ¨: {str(e)}")
                    continue
            
            raise ValueError("ëª¨ë“  XBRL ì ‘ê·¼ ë°©ë²•ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            print(f"XBRL ë·°ì–´ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            raise

    def extract_from_html_viewer(self, html_content, rcept_no):
        """HTML ë·°ì–´ì—ì„œ XBRL API í˜¸ì¶œ ì •ë³´ ì¶”ì¶œ"""
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            scripts = soup.find_all('script')
            
            for script in scripts:
                if script.string and 'viewDoc' in script.string:
                    # viewDoc í•¨ìˆ˜ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
                    patterns = [
                        r'viewDoc\("([^"]+)"\s*,\s*"([^"]*)"\s*,\s*"([^"]*)"\s*,\s*"([^"]+)"\)',
                        r'viewDoc\(\'([^\']+)\'\s*,\s*\'([^\']*)\'\s*,\s*\'([^\']*)\'\s*,\s*\'([^\']+)\'\)'
                    ]
                    
                    for pattern in patterns:
                        match = re.search(pattern, script.string)
                        if match:
                            doc_id, param2, lang, doc_type = match.groups()
                            print(f"ViewDoc íŒŒë¼ë¯¸í„°: doc_id={doc_id}, lang={lang}, type={doc_type}")
                            return self.fetch_xbrl_data_from_api(doc_id, lang, doc_type)
            
            raise ValueError("viewDoc í•¨ìˆ˜ í˜¸ì¶œì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            print(f"HTML ë·°ì–´ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            raise

    def fetch_xbrl_data_from_api(self, doc_id, lang, doc_type):
        """APIë¥¼ í†µí•´ XBRL ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        try:
            api_endpoints = [
                f"https://opendart.fss.or.kr/xbrl/viewer/data/{doc_id}?lang={lang}&type={doc_type}",
                f"https://opendart.fss.or.kr/xbrl/api/document/{doc_id}?lang={lang}&type={doc_type}",
                f"https://opendart.fss.or.kr/xbrl/data/{doc_id}.xml",
                f"https://dart.fss.or.kr/api/xbrl/{doc_id}.xml"
            ]
            
            session = requests.Session()
            session.headers.update({
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Referer': f"https://opendart.fss.or.kr/xbrl/viewer/main.do?rcpNo={doc_id}",
                'Accept': 'application/xml, text/xml, */*'
            })
            
            for endpoint in api_endpoints:
                try:
                    print(f"API í˜¸ì¶œ: {endpoint}")
                    response = session.get(endpoint, timeout=30)
                    
                    if response.status_code == 200:
                        content_type = response.headers.get('content-type', '')
                        if ('xml' in content_type or 
                            response.text.strip().startswith('<?xml')):
                            print(f"XBRL API ì„±ê³µ: {endpoint}")
                            return response.text
                            
                except requests.RequestException as e:
                    print(f"API í˜¸ì¶œ ì‹¤íŒ¨ {endpoint}: {str(e)}")
                    continue
            
            raise ValueError("ëª¨ë“  XBRL API ì—”ë“œí¬ì¸íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            print(f"XBRL API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
            raise

    # ê¸°ì¡´ ë©”ì†Œë“œë“¤ (parse_xbrl_data, extract_contexts ë“±)ì€ ë™ì¼í•˜ê²Œ ìœ ì§€
    def parse_xbrl_data(self, xbrl_content):
        """XBRL XML ë°ì´í„° íŒŒì‹±"""
        try:
            print("XBRL ë°ì´í„° íŒŒì‹± ì‹œì‘...")
            root = ET.fromstring(xbrl_content)
            print("XML íŒŒì‹± ì„±ê³µ")
            
            # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìë™ ê°ì§€
            for prefix, uri in root.attrib.items():
                if prefix.startswith('xmlns:'):
                    ns_prefix = prefix[6:]
                    self.xbrl_namespaces[ns_prefix] = uri
                elif prefix == 'xmlns':
                    self.xbrl_namespaces['default'] = uri
            
            print(f"ê°ì§€ëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤: {len(self.xbrl_namespaces)}ê°œ")
            
            parsed_data = {
                'contexts': self.extract_contexts(root),
                'financial_data': self.extract_financial_data(root),
                'company_info': self.extract_company_info(root),
                'metadata': self.extract_metadata(root)
            }
            
            print("XBRL ë°ì´í„° íŒŒì‹± ì™„ë£Œ")
            return parsed_data
            
        except ET.ParseError as e:
            print(f"XML íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            raise
        except Exception as e:
            print(f"XBRL ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
            raise

    def extract_contexts(self, root):
        """Context ì •ë³´ ì¶”ì¶œ"""
        contexts = {}
        context_elements = root.findall('.//xbrl:context', self.xbrl_namespaces)
        print(f"ë°œê²¬ëœ Context ìˆ˜: {len(context_elements)}")
        
        for context in context_elements:
            context_id = context.get('id')
            
            period_info = {}
            period = context.find('xbrl:period', self.xbrl_namespaces)
            if period is not None:
                instant = period.find('xbrl:instant', self.xbrl_namespaces)
                start_date = period.find('xbrl:startDate', self.xbrl_namespaces)
                end_date = period.find('xbrl:endDate', self.xbrl_namespaces)
                
                if instant is not None:
                    period_info['type'] = 'instant'
                    period_info['date'] = instant.text
                elif start_date is not None and end_date is not None:
                    period_info['type'] = 'duration'
                    period_info['start_date'] = start_date.text
                    period_info['end_date'] = end_date.text
            
            entity_info = {}
            entity = context.find('xbrl:entity', self.xbrl_namespaces)
            if entity is not None:
                identifier = entity.find('xbrl:identifier', self.xbrl_namespaces)
                if identifier is not None:
                    entity_info['scheme'] = identifier.get('scheme')
                    entity_info['value'] = identifier.text
            
            contexts[context_id] = {
                'period': period_info,
                'entity': entity_info
            }
        
        return contexts

    def extract_financial_data(self, root):
        """ì¬ë¬´ ë°ì´í„° ì¶”ì¶œ"""
        financial_data = {}
        
        key_items = {
            'Assets': ['ifrs-full:Assets', 'dart:Assets'],
            'Liabilities': ['ifrs-full:Liabilities', 'dart:Liabilities'],
            'Equity': ['ifrs-full:Equity', 'dart:Equity'],
            'CurrentAssets': ['ifrs-full:CurrentAssets', 'dart:CurrentAssets'],
            'NonCurrentAssets': ['ifrs-full:NoncurrentAssets', 'dart:NonCurrentAssets'],
            'CurrentLiabilities': ['ifrs-full:CurrentLiabilities', 'dart:CurrentLiabilities'],
            'Revenue': ['ifrs-full:Revenue', 'dart:Revenue'],
            'ProfitLoss': ['ifrs-full:ProfitLoss', 'dart:ProfitLoss'],
            'OperatingProfitLoss': ['ifrs-full:ProfitLossFromOperatingActivities', 'dart:OperatingIncomeLoss'],
            'GrossProfit': ['ifrs-full:GrossProfit', 'dart:GrossProfit']
        }
        
        total_elements_found = 0
        for item_name, possible_tags in key_items.items():
            for tag in possible_tags:
                elements = root.findall(f'.//{tag}', self.xbrl_namespaces)
                if elements:
                    item_data = []
                    for elem in elements:
                        context_ref = elem.get('contextRef')
                        unit_ref = elem.get('unitRef')
                        decimals = elem.get('decimals')
                        
                        item_data.append({
                            'value': elem.text,
                            'context_ref': context_ref,
                            'unit_ref': unit_ref,
                            'decimals': decimals
                        })
                        total_elements_found += 1
                    
                    financial_data[item_name] = item_data
                    break
        
        print(f"ì¶”ì¶œëœ ì¬ë¬´ ë°ì´í„° í•­ëª©: {len(financial_data)}ê°œ, ì´ ìš”ì†Œ: {total_elements_found}ê°œ")
        return financial_data

    def extract_company_info(self, root):
        """íšŒì‚¬ ì •ë³´ ì¶”ì¶œ"""
        company_info = {}
        
        company_tags = {
            'EntityName': ['ifrs-full:NameOfReportingEntityOrOtherMeansOfIdentification'],
            'BusinessDescription': ['ifrs-full:DescriptionOfNatureOfEntitysOperationsAndPrincipalActivities']
        }
        
        for info_name, possible_tags in company_tags.items():
            for tag in possible_tags:
                elements = root.findall(f'.//{tag}', self.xbrl_namespaces)
                if elements:
                    company_info[info_name] = elements[0].text
                    break
        
        return company_info

    def extract_metadata(self, root):
        """ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        metadata = {}
        
        schemaRef = root.find('.//link:schemaRef', self.xbrl_namespaces)
        if schemaRef is not None:
            metadata['schema_location'] = schemaRef.get('{http://www.w3.org/1999/xlink}href')
        
        return metadata

    def update_dart_reports(self):
        """DART ë³´ê³ ì„œ ë°ì´í„° ì—…ë°ì´íŠ¸ (XBRL ìš°ì„ , HTML í´ë°±)"""
        start_date, end_date = self.get_recent_dates()
        report_list = self.dart.list(self.corp_code, start_date, end_date, kind='A', final='T')
        
        if not report_list.empty:
            print(f"ë°œê²¬ëœ ë³´ê³ ì„œ: {len(report_list)}ê°œ")
            
            for _, report in report_list.iterrows():
                print(f"\nğŸ“‹ ë³´ê³ ì„œ ì²˜ë¦¬: {report['report_nm']} (ì ‘ìˆ˜ë²ˆí˜¸: {report['rcept_no']})")
                
                try:
                    # XBRL ë°©ì‹ ì‹œë„
                    try:
                        print("ğŸ”„ XBRL ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬ ì‹œë„...")
                        xbrl_content = self.download_xbrl_data(report['rcept_no'])
                        parsed_xbrl = self.parse_xbrl_data(xbrl_content)
                        
                        if parsed_xbrl['financial_data']:
                            structured_data = self.convert_xbrl_to_structured_data(parsed_xbrl)
                            self.update_sheets_with_xbrl_data(structured_data, report['rcept_no'])
                            print(f"âœ… XBRL ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬ ì™„ë£Œ: {report['report_nm']}")
                            continue
                        else:
                            print("âš ï¸ XBRLì—ì„œ ì¬ë¬´ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ. HTML ë°©ì‹ìœ¼ë¡œ ì „í™˜...")
                            
                    except Exception as xbrl_e:
                        print(f"âŒ XBRL ë°©ì‹ ì‹¤íŒ¨: {str(xbrl_e)}")
                        print("ğŸ”„ HTML ë°©ì‹ìœ¼ë¡œ ì „í™˜...")
                    
                    # HTML ë°©ì‹ í´ë°±
                    try:
                        print("ğŸ”„ HTML ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬...")
                        self.process_report_fallback(report['rcept_no'])
                        print(f"âœ… HTML ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬ ì™„ë£Œ: {report['report_nm']}")
                        
                    except Exception as html_e:
                        print(f"âŒ HTML ë°©ì‹ë„ ì‹¤íŒ¨: {str(html_e)}")
                        raise Exception(f"XBRLê³¼ HTML ë°©ì‹ ëª¨ë‘ ì‹¤íŒ¨: XBRL={str(xbrl_e)[:100]}, HTML={str(html_e)[:100]}")
                        
                except Exception as e:
                    print(f"âŒ ë³´ê³ ì„œ ì²˜ë¦¬ ì™„ì „ ì‹¤íŒ¨ ({report['rcept_no']}): {str(e)}")
                    continue
        else:
            print("ğŸ“­ ìµœê·¼ 3ê°œì›” ë‚´ ìƒˆë¡œìš´ ë³´ê³ ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

    def convert_xbrl_to_structured_data(self, parsed_xbrl):
        """XBRL ë°ì´í„°ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë³€í™˜"""
        structured_data = {
            'balance_sheet': {},
            'income_statement': {},
            'cash_flow': {},
            'company_info': parsed_xbrl.get('company_info', {}),
            'reporting_period': None
        }
        
        financial_mapping = {
            'balance_sheet': {
                'Assets': 'ìì‚°ì´ê³„',
                'Liabilities': 'ë¶€ì±„ì´ê³„',
                'Equity': 'ìë³¸ì´ê³„',
                'CurrentAssets': 'ìœ ë™ìì‚°',
                'NonCurrentAssets': 'ë¹„ìœ ë™ìì‚°',
                'CurrentLiabilities': 'ìœ ë™ë¶€ì±„'
            },
            'income_statement': {
                'Revenue': 'ë§¤ì¶œì•¡',
                'ProfitLoss': 'ë‹¹ê¸°ìˆœì´ìµ',
                'OperatingProfitLoss': 'ì˜ì—…ì´ìµ',
                'GrossProfit': 'ë§¤ì¶œì´ì´ìµ'
            }
        }
        
        financial_data = parsed_xbrl.get('financial_data', {})
        
        for statement_type, mapping in financial_mapping.items():
            for xbrl_item, korean_name in mapping.items():
                if xbrl_item in financial_data and financial_data[xbrl_item]:
                    item_data = financial_data[xbrl_item][0]
                    value = item_data['value']
                    
                    if value:
                        try:
                            cleaned_value = re.sub(r'[,\s]', '', value)
                            numeric_value = float(cleaned_value)
                            
                            decimals = item_data.get('decimals')
                            if decimals and decimals.isdigit():
                                numeric_value = numeric_value / (10 ** int(decimals))
                            
                            structured_data[statement_type][korean_name] = numeric_value
                        except ValueError:
                            structured_data[statement_type][korean_name] = value
        
        return structured_data

    def update_sheets_with_xbrl_data(self, structured_data, rcept_no):
        """XBRL êµ¬ì¡°í™” ë°ì´í„°ë¡œ ì‹œíŠ¸ ì—…ë°ì´íŠ¸"""
        try:
            financial_sheets = {
                '2. ì—°ê²°ì¬ë¬´ì œí‘œ': structured_data,
                '4. ì¬ë¬´ì œí‘œ': structured_data
            }
            
            for sheet_name, data in financial_sheets.items():
                try:
                    try:
                        worksheet = self.workbook.worksheet(sheet_name)
                    except gspread.exceptions.WorksheetNotFound:
                        worksheet = self.workbook.add_worksheet(sheet_name, 1000, 10)
                    
                    table_data = self.convert_to_table_format(data)
                    
                    if table_data:
                        worksheet.clear()
                        worksheet.append_rows(table_data)
                        print(f"âœ… XBRL ë°ì´í„°ë¡œ ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {sheet_name}")
                    
                except Exception as sheet_e:
                    print(f"âŒ ì‹œíŠ¸ {sheet_name} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(sheet_e)}")
                    continue
                    
        except Exception as e:
            print(f"âŒ XBRL ë°ì´í„° ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
            raise

    def convert_to_table_format(self, structured_data):
        """êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ í…Œì´ë¸” í˜•íƒœë¡œ ë³€í™˜"""
        table_data = []
        
        table_data.append(['êµ¬ë¶„', 'í•­ëª©', 'ê¸ˆì•¡', 'XBRL ì¶œì²˜'])
        
        if structured_data.get('balance_sheet'):
            table_data.append(['ì¬ë¬´ìƒíƒœí‘œ', '', '', ''])
            for item, value in structured_data['balance_sheet'].items():
                table_data.append(['', item, str(value), 'XBRL'])
        
        if structured_data.get('income_statement'):
            table_data.append(['ì†ìµê³„ì‚°ì„œ', '', '', ''])
            for item, value in structured_data['income_statement'].items():
                table_data.append(['', item, str(value), 'XBRL'])
        
        if structured_data.get('cash_flow'):
            table_data.append(['í˜„ê¸ˆíë¦„í‘œ', '', '', ''])
            for item, value in structured_data['cash_flow'].items():
                table_data.append(['', item, str(value), 'XBRL'])
        
        return table_data

    def process_report_fallback(self, rcept_no):
        """XBRL ì‹¤íŒ¨ ì‹œ HTML ë°©ì‹ìœ¼ë¡œ í´ë°±"""
        print(f"ğŸ”„ HTML í´ë°± ì²˜ë¦¬ ì‹œì‘: {rcept_no}")
        try:
            report_index = self.dart.sub_docs(rcept_no)
            target_docs = report_index[report_index['title'].isin(self.TARGET_SHEETS)]
            
            print(f"ğŸ“‘ ì²˜ë¦¬í•  ë¬¸ì„œ ìˆ˜: {len(target_docs)}")
            
            for _, doc in target_docs.iterrows():
                try:
                    print(f"ğŸ“„ ë¬¸ì„œ ì²˜ë¦¬: {doc['title']}")
                    self.update_worksheet_html(doc['title'], doc['url'])
                    print(f"âœ… ë¬¸ì„œ ì™„ë£Œ: {doc['title']}")
                except Exception as doc_e:
                    print(f"âŒ ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨ {doc['title']}: {str(doc_e)}")
                    continue
                    
        except Exception as e:
            print(f"âŒ HTML í´ë°± ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            raise

    def update_worksheet_html(self, sheet_name, url):
        """HTML ë°©ì‹ ì›Œí¬ì‹œíŠ¸ ì—…ë°ì´íŠ¸"""
        try:
            try:
                worksheet = self.workbook.worksheet(sheet_name)
            except gspread.exceptions.WorksheetNotFound:
                worksheet = self.workbook.add_worksheet(sheet_name, 1000, 10)
            
            print(f"ğŸŒ HTML ë°ì´í„° ë‹¤ìš´ë¡œë“œ: {url}")
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            
            if response.status_code == 200:
                print(f"ğŸ“Š HTML ì½˜í…ì¸  ì²˜ë¦¬ ì‹œì‘...")
                self.process_html_content(worksheet, response.text)
                print(f"âœ… HTML ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {sheet_name}")
            else:
                raise Exception(f"HTTP ì˜¤ë¥˜: {response.status_code}")
                
        except Exception as e:
            print(f"âŒ HTML ì›Œí¬ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
            raise

    def get_recent_dates(self):
        """ìµœê·¼ 3ê°œì›” ë‚ ì§œ ë²”ìœ„ ê³„ì‚°"""
        end_date = datetime.now()
        start_date = end_date - timedelta(days=90)
        return start_date.strftime('%Y%m%d'), end_date.strftime('%Y%m%d')

    def get_column_letter(self, col_num):
        """ìˆ«ìë¥¼ ì—‘ì…€ ì—´ ë¬¸ìë¡œ ë³€í™˜"""
        result = ""
        while col_num > 0:
            col_num, remainder = divmod(col_num - 1, 26)
            result = chr(65 + remainder) + result
        return result

    def send_telegram_message(self, message):
        """í…”ë ˆê·¸ë¨ìœ¼ë¡œ ë©”ì‹œì§€ ì „ì†¡"""
        if not self.telegram_bot_token or not self.telegram_channel_id:
            print("ğŸ“± í…”ë ˆê·¸ë¨ ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        try:
            url = f"https://api.telegram.org/bot{self.telegram_bot_token}/sendMessage"
            data = {
                "chat_id": self.telegram_channel_id,
                "text": message,
                "parse_mode": "HTML"
            }
            response = requests.post(url, data=data)
            response.raise_for_status()
            print("ğŸ“± í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì „ì†¡ ì™„ë£Œ")
        except Exception as e:
            print(f"ğŸ“± í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨: {str(e)}")

    def remove_parentheses(self, value):
        """ê´„í˜¸ ë‚´ìš© ì œê±°"""
        if not value:
            return value
        return re.sub(r'\s*\(.*?\)\s*', '', value).replace('%', '')

    def process_archive_data(self, archive, start_row, last_col):
        """ì•„ì¹´ì´ë¸Œ ë°ì´í„° ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)"""
        try:
            print(f"ğŸ“Š Archive ë°ì´í„° ì²˜ë¦¬ ì‹œì‘: í–‰={start_row}, ì—´={last_col}")
            
            # í˜„ì¬ ì‹œíŠ¸ í¬ê¸° í™•ì¸
            current_cols = archive.col_count
            current_col_letter = self.get_column_letter(current_cols)
            target_col_letter = self.get_column_letter(last_col)
            
            print(f"í˜„ì¬ ì‹œíŠ¸ ì—´ ìˆ˜: {current_cols} ({current_col_letter})")
            print(f"ëŒ€ìƒ ì—´: {last_col} ({target_col_letter})")
            
            # í•„ìš”í•œ ê²½ìš° ì‹œíŠ¸ í¬ê¸° ì¡°ì •
            if last_col >= current_cols:
                new_cols = last_col + 5
                print(f"ğŸ”§ ì‹œíŠ¸ í¬ê¸° ì¡°ì •: {current_cols} â†’ {new_cols}")
                archive.resize(rows=archive.row_count, cols=new_cols)
                time.sleep(2)
                print("âœ… ì‹œíŠ¸ í¬ê¸° ì¡°ì • ì™„ë£Œ")

            # ë°ì´í„° ìˆ˜ì§‘
            all_rows = archive.get_all_values()
            update_data = []
            sheet_cache = {}
            
            # ì²˜ë¦¬í•  í–‰ë“¤ ê·¸ë£¹í™”
            sheet_rows = {}
            processed_count = 0
            
            for row_idx in range(start_row - 1, len(all_rows)):
                if len(all_rows[row_idx]) < 5:
                    continue
                    
                sheet_name = all_rows[row_idx][0]
                if not sheet_name:
                    continue
                
                if sheet_name not in sheet_rows:
                    sheet_rows[sheet_name] = []
                    
                sheet_rows[sheet_name].append({
                    'row_idx': row_idx + 1,
                    'keyword': all_rows[row_idx][1],
                    'n': all_rows[row_idx][2],
                    'x': all_rows[row_idx][3],
                    'y': all_rows[row_idx][4]
                })
                processed_count += 1
            
            print(f"ğŸ“‹ ì²˜ë¦¬í•  ì‹œíŠ¸ ìˆ˜: {len(sheet_rows)}, ì´ í–‰ ìˆ˜: {processed_count}")
            
            # ì‹œíŠ¸ë³„ ë°ì´í„° ì²˜ë¦¬
            for sheet_name, rows in sheet_rows.items():
                try:
                    print(f"\nğŸ” ì‹œíŠ¸ '{sheet_name}' ì²˜ë¦¬ ì¤‘ (í•­ëª©: {len(rows)}ê°œ)")
                    
                    # ì‹œíŠ¸ ë°ì´í„° ìºì‹±
                    if sheet_name not in sheet_cache:
                        try:
                            search_sheet = self.workbook.worksheet(sheet_name)
                            sheet_data = search_sheet.get_all_values()
                            df = pd.DataFrame(sheet_data)
                            sheet_cache[sheet_name] = df
                            print(f"âœ… ì‹œíŠ¸ ë°ì´í„° ë¡œë“œ: {df.shape}")
                        except gspread.exceptions.WorksheetNotFound:
                            print(f"âš ï¸ ì‹œíŠ¸ '{sheet_name}' ì—†ìŒ. ê±´ë„ˆëœ€.")
                            continue
                    
                    df = sheet_cache[sheet_name]
                    
                    # ê° í–‰ì˜ í‚¤ì›Œë“œ ê²€ìƒ‰
                    for row in rows:
                        try:
                            keyword = row['keyword']
                            if not all([keyword, row['n'], row['x'], row['y']]):
                                continue
                            
                            n, x, y = int(row['n']), int(row['x']), int(row['y'])
                            
                            # í‚¤ì›Œë“œ ìœ„ì¹˜ ê²€ìƒ‰
                            keyword_positions = []
                            for idx, df_row in df.iterrows():
                                for col_idx, value in enumerate(df_row):
                                    if str(value).strip() == keyword.strip():
                                        keyword_positions.append((idx, col_idx))
                            
                            if keyword_positions and len(keyword_positions) >= n:
                                target_pos = keyword_positions[n - 1]
                                target_row = target_pos[0] + y
                                target_col = target_pos[1] + x
                                
                                if (0 <= target_row < df.shape[0] and 
                                    0 <= target_col < df.shape[1]):
                                    value = df.iat[target_row, target_col]
                                    cleaned_value = self.remove_parentheses(str(value))
                                    update_data.append((row['row_idx'], cleaned_value))
                                    print(f"âœ… ê°’ ë°œê²¬: {keyword} â†’ {cleaned_value}")
                                else:
                                    print(f"âš ï¸ ë²”ìœ„ ì´ˆê³¼: {keyword}")
                            else:
                                print(f"âš ï¸ í‚¤ì›Œë“œ ë¯¸ë°œê²¬: {keyword}")
                                
                        except Exception as row_e:
                            print(f"âŒ í–‰ ì²˜ë¦¬ ì˜¤ë¥˜: {str(row_e)}")
                            continue
                
                except Exception as sheet_e:
                    print(f"âŒ ì‹œíŠ¸ '{sheet_name}' ì²˜ë¦¬ ì˜¤ë¥˜: {str(sheet_e)}")
                    continue
            
            print(f"\nğŸ“Š ì—…ë°ì´íŠ¸í•  ë°ì´í„°: {len(update_data)}ê°œ")
            
            # ë°ì´í„° ì—…ë°ì´íŠ¸
            if update_data:
                self.update_archive_column(archive, update_data, target_col_letter, last_col)
                
                # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
                today = datetime.now()
                three_months_ago = today - timedelta(days=90)
                year = str(three_months_ago.year)[2:]
                quarter = (three_months_ago.month - 1) // 3 + 1
                quarter_text = f"{quarter}Q{year}"
                
                meta_updates = [
                    {'range': 'J1', 'values': [[today.strftime('%Y-%m-%d')]]},
                    {'range': f'{target_col_letter}1', 'values': [['1']]},
                    {'range': f'{target_col_letter}5', 'values': [[today.strftime('%Y-%m-%d')]]},
                    {'range': f'{target_col_letter}6', 'values': [[quarter_text]]}
                ]
                
                archive.batch_update(meta_updates)
                print(f"âœ… ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ (ë¶„ê¸°: {quarter_text})")
                
                # í…”ë ˆê·¸ë¨ ì•Œë¦¼
                message = (
                    f"ğŸ”„ DART ì—…ë°ì´íŠ¸ ì™„ë£Œ\n\n"
                    f"â€¢ ì¢…ëª©: {self.company_name} ({self.corp_code})\n"
                    f"â€¢ ë¶„ê¸°: {quarter_text}\n"
                    f"â€¢ ì—…ë°ì´íŠ¸ ì¼ì‹œ: {today.strftime('%Y-%m-%d %H:%M:%S')}\n"
                    f"â€¢ ì²˜ë¦¬ëœ í–‰: {len(update_data)}ê°œ\n"
                    f"â€¢ ì‹œíŠ¸ ì—´: {target_col_letter} (#{last_col})"
                )
                self.send_telegram_message(message)
                
            else:
                print("âš ï¸ ì—…ë°ì´íŠ¸í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            error_msg = f"Archive ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"
            print(f"âŒ {error_msg}")
            self.send_telegram_message(f"âŒ {error_msg}")
            raise

    def update_archive_column(self, archive, update_data, target_col_letter, last_col):
        """Archive ì—´ ë°ì´í„° ì—…ë°ì´íŠ¸"""
        try:
            min_row = min(row for row, _ in update_data)
            max_row = max(row for row, _ in update_data)
            
            # ì—…ë°ì´íŠ¸í•  ë°ì´í„° ì¤€ë¹„
            column_data = [''] * (max_row - min_row + 1)
            for row, value in update_data:
                adjusted_row = row - min_row
                column_data[adjusted_row] = value
            
            # 2D ë°°ì—´ë¡œ ë³€í™˜ (Google Sheets API ìš”êµ¬ì‚¬í•­)
            column_data_2d = [[value] for value in column_data]
            
            range_label = f'{target_col_letter}{min_row}:{target_col_letter}{max_row}'
            print(f"ğŸ“ ì—…ë°ì´íŠ¸ ë²”ìœ„: {range_label}")
            
            archive.batch_update([{
                'range': range_label,
                'values': column_data_2d
            }])
            
            print(f"âœ… ì»¬ëŸ¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {min_row}~{max_row} í–‰")
            
        except Exception as e:
            print(f"âŒ ì»¬ëŸ¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
            raise


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        import sys
        
        def log(msg):
            print(f"ğŸ¤– {msg}")
            sys.stdout.flush()
        
        COMPANY_INFO = {
            'code': '307950',
            'name': 'í˜„ëŒ€ì˜¤í† ì—ë²„',
            'spreadsheet_var': 'AUTOEVER_SPREADSHEET_ID'
        }
        
        log(f"{COMPANY_INFO['name']}({COMPANY_INFO['code']}) XBRL ê¸°ë°˜ ë³´ê³ ì„œ ì—…ë°ì´íŠ¸ ì‹œì‘")
        
        try:
            updater = XBRLDartReportUpdater(
                COMPANY_INFO['code'], 
                COMPANY_INFO['spreadsheet_var'],
                COMPANY_INFO['name']
            )
            
            # XBRL ê¸°ë°˜ ë³´ê³ ì„œ ì—…ë°ì´íŠ¸
            log("ğŸ“‹ DART ë³´ê³ ì„œ ì—…ë°ì´íŠ¸ ì‹œì‘...")
            updater.update_dart_reports()
            log("âœ… DART ë³´ê³ ì„œ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            
            # Archive ì‹œíŠ¸ ì²˜ë¦¬
            log("ğŸ“Š Archive ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì‹œì‘...")
            archive = updater.workbook.worksheet('Dart_Archive')
            
            sheet_values = archive.get_all_values()
            if not sheet_values:
                raise ValueError("Dart_Archive ì‹œíŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            
            last_col = len(sheet_values[0])
            control_value = archive.cell(1, last_col).value
            start_row = 10
            
            if control_value:
                last_col += 1
            
            log(f"Archive ì²˜ë¦¬: ì‹œì‘í–‰={start_row}, ëŒ€ìƒì—´={last_col}")
            updater.process_archive_data(archive, start_row, last_col)
            log("âœ… Archive ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            
            log("ğŸ‰ ì „ì²´ ì‘ì—… ì™„ë£Œ!")
            
        except Exception as e:
            log(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            if 'updater' in locals():
                updater.send_telegram_message(
                    f"âŒ XBRL DART ì—…ë°ì´íŠ¸ ì‹¤íŒ¨\n\n"
                    f"â€¢ ì¢…ëª©: {COMPANY_INFO['name']} ({COMPANY_INFO['code']})\n"
                    f"â€¢ ì˜¤ë¥˜: {str(e)}"
                )
            raise

    except Exception as e:
        print(f"ğŸ’¥ ì „ì²´ ì‘ì—… ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {str(e)}")
        print(f"ğŸ” ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
        raise e

if __name__ == "__main__":
    main()
